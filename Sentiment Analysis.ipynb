{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7dd054e",
   "metadata": {},
   "source": [
    "# [Fellowship.ai](https://www.fellowship.ai/) Internship"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79b37c1",
   "metadata": {},
   "source": [
    "## Candidate Name : [Abdul Jaweed](https://www.linkedin.com/in/abdul-jaweed-datascientist/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88afa2f6",
   "metadata": {},
   "source": [
    "## NLP Challenge: \n",
    " \n",
    "### IMDB [Dataset](https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews) of 50K Movie Reviews to perform Sentiment analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d483060e",
   "metadata": {},
   "source": [
    "## About Dataset\n",
    "\n",
    "IMDB dataset having 50K movie reviews for natural language processing or Text analytics.\n",
    "\n",
    "This is a dataset for binary sentiment classification containing substantially more data than previous benchmark datasets. We provide a set of 25,000 highly polar movie reviews for training and 25,000 for testing. So, predict the number of positive and negative reviews using either classification or deep learning algorithms.\n",
    "\n",
    "For more dataset information, please go through the following [link](http://ai.stanford.edu/~amaas/data/sentiment/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f3cff2",
   "metadata": {},
   "source": [
    "**************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d7112bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b032395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Dataset\n",
    "\n",
    "df = pd.read_csv(\"IMDB Dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ab70fbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing Top 5 Rows\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b127af26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>I thought this movie did a down right good job...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>I am a Catholic taught in parochial elementary...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>I'm going to have to disagree with the previou...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>No one expects the Star Trek movies to be high...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "49995  I thought this movie did a down right good job...  positive\n",
       "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
       "49997  I am a Catholic taught in parochial elementary...  negative\n",
       "49998  I'm going to have to disagree with the previou...  negative\n",
       "49999  No one expects the Star Trek movies to be high...  negative"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing Last 5 Rows\n",
    "\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74629096",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23864</th>\n",
       "      <td>Okay, I like to give the benefit of the doubt....</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34603</th>\n",
       "      <td>First the premise stinks...little boy likes to...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46418</th>\n",
       "      <td>Very rarely do I give less rave reviews on a s...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23021</th>\n",
       "      <td>I can't believe I missed this one. Made in 197...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23565</th>\n",
       "      <td>Wonderfully put together..I wish there was a f...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30130</th>\n",
       "      <td>I heard the stories of the ravers in the movie...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42151</th>\n",
       "      <td>Watched this film with an audience of....5 in ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17610</th>\n",
       "      <td>In 1982, two films were released within weeks ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49656</th>\n",
       "      <td>Caught this movie on TV and I watched it again...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42038</th>\n",
       "      <td>A good film, and one I'll watch a number of ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "23864  Okay, I like to give the benefit of the doubt....  negative\n",
       "34603  First the premise stinks...little boy likes to...  negative\n",
       "46418  Very rarely do I give less rave reviews on a s...  negative\n",
       "23021  I can't believe I missed this one. Made in 197...  positive\n",
       "23565  Wonderfully put together..I wish there was a f...  positive\n",
       "30130  I heard the stories of the ravers in the movie...  negative\n",
       "42151  Watched this film with an audience of....5 in ...  negative\n",
       "17610  In 1982, two films were released within weeks ...  positive\n",
       "49656  Caught this movie on TV and I watched it again...  positive\n",
       "42038  A good film, and one I'll watch a number of ti...  positive"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing Random 10 Rows\n",
    "\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c12083d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Rows    :  50000\n",
      "Total Number of Columns :  2\n"
     ]
    }
   ],
   "source": [
    "# Printing the Total Numbers of Rows and Columns\n",
    "\n",
    "print(\"Total Number of Rows    : \", df.shape[0])\n",
    "print(\"Total Number of Columns : \", df.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48e79e78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   review     50000 non-null  object\n",
      " 1   sentiment  50000 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 781.4+ KB\n"
     ]
    }
   ],
   "source": [
    "# Printing Dataset Information\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd8836f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review       0\n",
       "sentiment    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing Null Values\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "caa922a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "418"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing Duplicated Values\n",
    "\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19c63bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing Duplicated Values\n",
    "\n",
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c84184f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing Duplicated Values After Removing Duplicated\n",
    "\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "737f57b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Rows    :  49582\n",
      "Total Number of Columns :  2\n"
     ]
    }
   ],
   "source": [
    "# Printing the Total Numbers of Rows and Columns After Removing Duplicated Values\n",
    "\n",
    "print(\"Total Number of Rows    : \", df.shape[0])\n",
    "print(\"Total Number of Columns : \", df.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "259724ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.<br /><br />The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.<br /><br />It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. Em City is home to many..Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.<br /><br />I would say the main appeal of the show is due to the fact that it goes where other shows wouldn't dare. Forget pretty pictures painted for mainstream audiences, forget charm, forget romance...OZ doesn't mess around. The first episode I ever saw struck me as so nasty it was surreal, I couldn't say I was ready for it, but as I watched more, I developed a taste for Oz, and got accustomed to the high levels of graphic violence. Not just violence, but injustice (crooked guards who'll be sold out for a nickel, inmates who'll kill on order and get away with it, well mannered, middle class inmates being turned into prison bitches due to their lack of street skills or prison experience) Watching Oz, you may become comfortable with what is uncomfortable viewing....thats if you can get in touch with your darker side.\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing First review column\n",
    "\n",
    "df.review[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e2bc9368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Probably my all-time favorite movie, a story o...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49983</th>\n",
       "      <td>I loved it, having been a fan of the original ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49985</th>\n",
       "      <td>Imaginary Heroes is clearly the best film of t...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49989</th>\n",
       "      <td>I got this one a few weeks ago and love it! It...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49992</th>\n",
       "      <td>John Garfield plays a Marine who is blinded by...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>I thought this movie did a down right good job...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24884 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "0      One of the other reviewers has mentioned that ...  positive\n",
       "1      A wonderful little production. <br /><br />The...  positive\n",
       "2      I thought this was a wonderful way to spend ti...  positive\n",
       "4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
       "5      Probably my all-time favorite movie, a story o...  positive\n",
       "...                                                  ...       ...\n",
       "49983  I loved it, having been a fan of the original ...  positive\n",
       "49985  Imaginary Heroes is clearly the best film of t...  positive\n",
       "49989  I got this one a few weeks ago and love it! It...  positive\n",
       "49992  John Garfield plays a Marine who is blinded by...  positive\n",
       "49995  I thought this movie did a down right good job...  positive\n",
       "\n",
       "[24884 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing All Positive Sentiment\n",
    "\n",
    "df[df.sentiment=='positive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c018813",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>This show was an amazing, fresh &amp; innovative i...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Encouraged by the positive comments about this...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Phil the Alien is one of those quirky films wh...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>I saw this movie when I was about 12 when it c...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49994</th>\n",
       "      <td>This is your typical junk comedy.&lt;br /&gt;&lt;br /&gt;T...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>I am a Catholic taught in parochial elementary...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>I'm going to have to disagree with the previou...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>No one expects the Star Trek movies to be high...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24698 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "3      Basically there's a family where a little boy ...  negative\n",
       "7      This show was an amazing, fresh & innovative i...  negative\n",
       "8      Encouraged by the positive comments about this...  negative\n",
       "10     Phil the Alien is one of those quirky films wh...  negative\n",
       "11     I saw this movie when I was about 12 when it c...  negative\n",
       "...                                                  ...       ...\n",
       "49994  This is your typical junk comedy.<br /><br />T...  negative\n",
       "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
       "49997  I am a Catholic taught in parochial elementary...  negative\n",
       "49998  I'm going to have to disagree with the previou...  negative\n",
       "49999  No one expects the Star Trek movies to be high...  negative\n",
       "\n",
       "[24698 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing All Negative Sentiment\n",
    "\n",
    "df[df.sentiment=='negative']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "567df609",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive    24884\n",
       "negative    24698\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing the count of each unique value in the Sentiment column\n",
    "\n",
    "df.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "da0b1d08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive    0.501876\n",
       "negative    0.498124\n",
       "Name: sentiment, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing the counts would be converted to relative frequencies\n",
    "\n",
    "df.sentiment.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "97fe6084",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 900x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the Bar Chart of Sentiment Column\n",
    "\n",
    "plt.figure(figsize = (9,6))\n",
    "sns.countplot(x=df.sentiment)\n",
    "plt.title(\"Bar Chart of Sentiment Column\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "66740ea0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the Pie Chart of Sentiment Column\n",
    "\n",
    "df.sentiment.value_counts().plot(kind='pie', autopct='%1.1f%%', title='Pie Chart of Sentiment Column', legend=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef0b22c",
   "metadata": {},
   "source": [
    "### Text Cleaning\n",
    "\n",
    "- Removing Html tags\n",
    "- Converting every thing to lowercase \n",
    "- Removing special characters\n",
    "- Removing Stop words\n",
    "- Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "29fed415",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In sentiment column converting positive to 1 and negative to 0\n",
    "\n",
    "df.sentiment = df.sentiment.replace({'positive':1, 'negative':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0c3ee411",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    24884\n",
       "0    24698\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74121831",
   "metadata": {},
   "source": [
    "**Removing Html tag**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "941239ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.<br /><br />The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.<br /><br />It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. Em City is home to many..Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.<br /><br />I would say the main appeal of the show is due to the fact that it goes where other shows wouldn't dare. Forget pretty pictures painted for mainstream audiences, forget charm, forget romance...OZ doesn't mess around. The first episode I ever saw struck me as so nasty it was surreal, I couldn't say I was ready for it, but as I watched more, I developed a taste for Oz, and got accustomed to the high levels of graphic violence. Not just violence, but injustice (crooked guards who'll be sold out for a nickel, inmates who'll kill on order and get away with it, well mannered, middle class inmates being turned into prison bitches due to their lack of street skills or prison experience) Watching Oz, you may become comfortable with what is uncomfortable viewing....thats if you can get in touch with your darker side.\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In Review column first row before removing html tag\n",
    "\n",
    "df.review[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8ed20686",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. Em City is home to many..Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.I would say the main appeal of the show is due to the fact that it goes where other shows wouldn't dare. Forget pretty pictures painted for mainstream audiences, forget charm, forget romance...OZ doesn't mess around. The first episode I ever saw struck me as so nasty it was surreal, I couldn't say I was ready for it, but as I watched more, I developed a taste for Oz, and got accustomed to the high levels of graphic violence. Not just violence, but injustice (crooked guards who'll be sold out for a nickel, inmates who'll kill on order and get away with it, well mannered, middle class inmates being turned into prison bitches due to their lack of street skills or prison experience) Watching Oz, you may become comfortable with what is uncomfortable viewing....thats if you can get in touch with your darker side.\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# removing html tag\n",
    "\n",
    "import re\n",
    "clean = re.compile('<.*?>')\n",
    "\n",
    "# In Review column first row after removing html tag\n",
    "\n",
    "re.sub(clean, '',  df.iloc[0].review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "035560bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.<br /><br />The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.<br /><br />It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. Em City is home to many..Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.<br /><br />I would say the main appeal of the show is due to the fact that it goes where other shows wouldn't dare. Forget pretty pictures painted for mainstream audiences, forget charm, forget romance...OZ doesn't mess around. The first episode I ever saw struck me as so nasty it was surreal, I couldn't say I was ready for it, but as I watched more, I developed a taste for Oz, and got accustomed to the high levels of graphic violence. Not just violence, but injustice (crooked guards who'll be sold out for a nickel, inmates who'll kill on order and get away with it, well mannered, middle class inmates being turned into prison bitches due to their lack of street skills or prison experience) Watching Oz, you may become comfortable with what is uncomfortable viewing....thats if you can get in touch with your darker side.\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In Review column first row after removing html tag\n",
    "\n",
    "df.review[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e5997f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean html tags\n",
    "\n",
    "def clean_html(text):\n",
    "    clean = re.compile('<.*?>')\n",
    "    return re.sub(clean, '', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7f361ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appling Removing html tags function\n",
    "\n",
    "df.review = df.review.apply(clean_html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c67d751",
   "metadata": {},
   "source": [
    "**Converting every thing to lowercase**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "44bbbe7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting everything to lower\n",
    "\n",
    "def convert_lower(text):\n",
    "    return text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4e42ed91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appling convert_lower function\n",
    "\n",
    "df.review = df.review.apply(convert_lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f1c1f636",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"one of the other reviewers has mentioned that after watching just 1 oz episode you'll be hooked. they are right, as this is exactly what happened with me.the first thing that struck me about oz was its brutality and unflinching scenes of violence, which set in right from the word go. trust me, this is not a show for the faint hearted or timid. this show pulls no punches with regards to drugs, sex or violence. its is hardcore, in the classic use of the word.it is called oz as that is the nickname given to the oswald maximum security state penitentary. it focuses mainly on emerald city, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. em city is home to many..aryans, muslims, gangstas, latinos, christians, italians, irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.i would say the main appeal of the show is due to the fact that it goes where other shows wouldn't dare. forget pretty pictures painted for mainstream audiences, forget charm, forget romance...oz doesn't mess around. the first episode i ever saw struck me as so nasty it was surreal, i couldn't say i was ready for it, but as i watched more, i developed a taste for oz, and got accustomed to the high levels of graphic violence. not just violence, but injustice (crooked guards who'll be sold out for a nickel, inmates who'll kill on order and get away with it, well mannered, middle class inmates being turned into prison bitches due to their lack of street skills or prison experience) watching oz, you may become comfortable with what is uncomfortable viewing....thats if you can get in touch with your darker side.\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In Review column first row after converting everything to lower\n",
    "\n",
    "df.review[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c4e016",
   "metadata": {},
   "source": [
    "**Removing special characters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4188cf36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to remove special characters\n",
    "\n",
    "def remove_special_chars(text):\n",
    "    clean = re.compile('[^a-zA-Z ]')\n",
    "    return re.sub(clean, '', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a0a0106c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appling remove_special_chars function\n",
    "\n",
    "df.review = df.review.apply(remove_special_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a2a6088b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'one of the other reviewers has mentioned that after watching just  oz episode youll be hooked they are right as this is exactly what happened with methe first thing that struck me about oz was its brutality and unflinching scenes of violence which set in right from the word go trust me this is not a show for the faint hearted or timid this show pulls no punches with regards to drugs sex or violence its is hardcore in the classic use of the wordit is called oz as that is the nickname given to the oswald maximum security state penitentary it focuses mainly on emerald city an experimental section of the prison where all the cells have glass fronts and face inwards so privacy is not high on the agenda em city is home to manyaryans muslims gangstas latinos christians italians irish and moreso scuffles death stares dodgy dealings and shady agreements are never far awayi would say the main appeal of the show is due to the fact that it goes where other shows wouldnt dare forget pretty pictures painted for mainstream audiences forget charm forget romanceoz doesnt mess around the first episode i ever saw struck me as so nasty it was surreal i couldnt say i was ready for it but as i watched more i developed a taste for oz and got accustomed to the high levels of graphic violence not just violence but injustice crooked guards wholl be sold out for a nickel inmates wholl kill on order and get away with it well mannered middle class inmates being turned into prison bitches due to their lack of street skills or prison experience watching oz you may become comfortable with what is uncomfortable viewingthats if you can get in touch with your darker side'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In Review column first row after removing special characters\n",
    "\n",
    "df.review[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6995ec2a",
   "metadata": {},
   "source": [
    "**Removing Stop words**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4af96315",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ad80e1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing Stopwords from Review Column\n",
    "\n",
    "sw_list = stopwords.words('english')\n",
    "\n",
    "df.review = df.review.apply(lambda x: [item for item in x.split() if item not in sw_list]).apply(lambda x:\" \".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9f76330f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'one reviewers mentioned watching oz episode youll hooked right exactly happened methe first thing struck oz brutality unflinching scenes violence set right word go trust show faint hearted timid show pulls punches regards drugs sex violence hardcore classic use wordit called oz nickname given oswald maximum security state penitentary focuses mainly emerald city experimental section prison cells glass fronts face inwards privacy high agenda em city home manyaryans muslims gangstas latinos christians italians irish moreso scuffles death stares dodgy dealings shady agreements never far awayi would say main appeal show due fact goes shows wouldnt dare forget pretty pictures painted mainstream audiences forget charm forget romanceoz doesnt mess around first episode ever saw struck nasty surreal couldnt say ready watched developed taste oz got accustomed high levels graphic violence violence injustice crooked guards wholl sold nickel inmates wholl kill order get away well mannered middle class inmates turned prison bitches due lack street skills prison experience watching oz may become comfortable uncomfortable viewingthats get touch darker side'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In Review column first row after removing Stopwords\n",
    "\n",
    "df.review[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd7806c",
   "metadata": {},
   "source": [
    "**Apply Lemmatization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d22a2168",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "eade8cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('wordnet')\n",
    "#nltk.download('omw-1.4')\n",
    "#nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d962c887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for Lemmatization\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    lemmatized_text = \" \".join([lemmatizer.lemmatize(token) for token in tokens])\n",
    "    return lemmatized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "df95753b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'one reviewers mentioned watching oz episode youll hooked right exactly happened methe first thing struck oz brutality unflinching scenes violence set right word go trust show faint hearted timid show pulls punches regards drugs sex violence hardcore classic use wordit called oz nickname given oswald maximum security state penitentary focuses mainly emerald city experimental section prison cells glass fronts face inwards privacy high agenda em city home manyaryans muslims gangstas latinos christians italians irish moreso scuffles death stares dodgy dealings shady agreements never far awayi would say main appeal show due fact goes shows wouldnt dare forget pretty pictures painted mainstream audiences forget charm forget romanceoz doesnt mess around first episode ever saw struck nasty surreal couldnt say ready watched developed taste oz got accustomed high levels graphic violence violence injustice crooked guards wholl sold nickel inmates wholl kill order get away well mannered middle class inmates turned prison bitches due lack street skills prison experience watching oz may become comfortable uncomfortable viewingthats get touch darker side'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In Review column first row before applying Lemmatization Function\n",
    "\n",
    "df.review[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "81071c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying Lemmatization Function\n",
    "\n",
    "df.review = df.review.apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b418f8e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'one reviewer mentioned watching oz episode youll hooked right exactly happened methe first thing struck oz brutality unflinching scene violence set right word go trust show faint hearted timid show pull punch regard drug sex violence hardcore classic use wordit called oz nickname given oswald maximum security state penitentary focus mainly emerald city experimental section prison cell glass front face inwards privacy high agenda em city home manyaryans muslim gangsta latino christian italian irish moreso scuffle death stare dodgy dealing shady agreement never far awayi would say main appeal show due fact go show wouldnt dare forget pretty picture painted mainstream audience forget charm forget romanceoz doesnt mess around first episode ever saw struck nasty surreal couldnt say ready watched developed taste oz got accustomed high level graphic violence violence injustice crooked guard wholl sold nickel inmate wholl kill order get away well mannered middle class inmate turned prison bitch due lack street skill prison experience watching oz may become comfortable uncomfortable viewingthats get touch darker side'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In Review column first row after applying Lemmatization Function\n",
    "\n",
    "df.review[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b6cab747",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['BOW'] = df.review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2f559f94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>BOW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one reviewer mentioned watching oz episode you...</td>\n",
       "      <td>1</td>\n",
       "      <td>one reviewer mentioned watching oz episode you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wonderful little production filming technique ...</td>\n",
       "      <td>1</td>\n",
       "      <td>wonderful little production filming technique ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thought wonderful way spend time hot summer we...</td>\n",
       "      <td>1</td>\n",
       "      <td>thought wonderful way spend time hot summer we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically there family little boy jake think t...</td>\n",
       "      <td>0</td>\n",
       "      <td>basically there family little boy jake think t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter matteis love time money visually stunni...</td>\n",
       "      <td>1</td>\n",
       "      <td>petter matteis love time money visually stunni...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment  \\\n",
       "0  one reviewer mentioned watching oz episode you...          1   \n",
       "1  wonderful little production filming technique ...          1   \n",
       "2  thought wonderful way spend time hot summer we...          1   \n",
       "3  basically there family little boy jake think t...          0   \n",
       "4  petter matteis love time money visually stunni...          1   \n",
       "\n",
       "                                                 BOW  \n",
       "0  one reviewer mentioned watching oz episode you...  \n",
       "1  wonderful little production filming technique ...  \n",
       "2  thought wonderful way spend time hot summer we...  \n",
       "3  basically there family little boy jake think t...  \n",
       "4  petter matteis love time money visually stunni...  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77889287",
   "metadata": {},
   "source": [
    "# Model Building\n",
    "\n",
    "In summary, the steps involved in building a machine learning model include data preparation, splitting the data into training, validation, and test sets, choosing an appropriate model, training the model on the training data, evaluating the model on the validation and test sets, fine-tuning the model based on the evaluation results, and finally deploying the model for making predictions on new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "763ab9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b206edef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        one reviewer mentioned watching oz episode you...\n",
       "1        wonderful little production filming technique ...\n",
       "2        thought wonderful way spend time hot summer we...\n",
       "3        basically there family little boy jake think t...\n",
       "4        petter matteis love time money visually stunni...\n",
       "                               ...                        \n",
       "49995    thought movie right good job wasnt creative or...\n",
       "49996    bad plot bad dialogue bad acting idiotic direc...\n",
       "49997    catholic taught parochial elementary school nu...\n",
       "49998    im going disagree previous comment side maltin...\n",
       "49999    one expects star trek movie high art fan expec...\n",
       "Name: BOW, Length: 49582, dtype: object"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "48ffdfbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "43f5a625",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1\n",
       "1        1\n",
       "2        1\n",
       "3        0\n",
       "4        1\n",
       "        ..\n",
       "49995    1\n",
       "49996    0\n",
       "49997    0\n",
       "49998    0\n",
       "49999    0\n",
       "Name: sentiment, Length: 49582, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82a86b7",
   "metadata": {},
   "source": [
    "## Train Test Split\n",
    "\n",
    "Train-test split is a technique used in machine learning to evaluate the performance of a model on new, unseen data. It involves splitting the available data into two subsets - a training set and a test set. The model is trained on the training set and its performance is evaluated on the test set. This allows the model to learn patterns from the training data and be evaluated on how well it can generalize to new data. The goal of train-test split is to ensure that the model is not overfitting the training data and can perform well on new data. Typically, around 70-80% of the data is used for training, and the remaining 20-30% is used for testing. Cross-validation is another technique that can be used in combination with train-test split to further evaluate the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ee92b106",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_bow, X_test_bow, y_train_bow, y_test_bow = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94af4e42",
   "metadata": {},
   "source": [
    "## Bag of Word Representation\n",
    "\n",
    "We call vectorization the general process of turning a collection of text documents into numerical feature vectors. This specific strategy (tokenization, counting and normalization) is called the Bag of Words or \"Bag of n-grams\" representation. Documents are described by word occurrences while completely ignoring the relative position information of the words in the document.\n",
    "\n",
    "We will use `CountVectorizer` to **convert text into a matrix of token count**.\n",
    "\n",
    "`Bag of Words`: https://machinelearningmastery.com/gentle-introduction-bag-words-model/\n",
    "\n",
    "`Code Example`: https://machinelearningmastery.com/prepare-text-data-machine-learning-scikit-learn/  \n",
    "\n",
    "**We are going to perform below mentioned steps to understand the entire process:**  \n",
    "a. Converting text to numerical vectors with the help of `CountVectorizer`  \n",
    "b. Understand `fit` and `transform`  \n",
    "c. Looking at `vocabulary_`  \n",
    "d. Converting sparse matrix to dense matrix using `toarray()`  \n",
    "e. Understanding `n_gram`  \n",
    "\n",
    "### Advantages\n",
    "1. It is simple to understand and implement like OneHotEncoding.\n",
    "2. We have a fixed length encoding for any sequence of arbitrary length.\n",
    "3. Documents with same words/vocabulary will have similar representation. So if two documents have a similar vocabulary, they’ll be closer to each other in the vector space and vice versa.\n",
    "\n",
    "### Disadvantages\n",
    "1. The size of vector increases with the size of the vocabulary. Thus, sparsity continues to be a problem. One way to control it is by limiting the vocabulary to n number of the most frequent words.\n",
    "2. It does not capture the similarity between different words that mean the same thing. i.e. Semantic Meaning is not captured.\n",
    "> a. \"walk\", \"walked\", and \"walking\". BoW vectors of all three tokens will be equally apart.  \n",
    "> b. \"search\" and \"explore\" are synonyms. BoW won't capture the semantic similarity of these words.\n",
    "3. This representation does not have any way to handle out of vocabulary (OOV) words (i.e., new words that were not seen in the corpus that was used to build the vectorizer).\n",
    "4. As the name indicates, it is a “bag” of words. Word order information is lost in this representation. One way to control it is by using n-grams.\n",
    "5. It suffers from **curse of high dimensionality.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "992d58d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ba356d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7f816fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_bow = vocab.fit_transform(X_train_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "516b1591",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_bow = vocab.transform(X_test_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e054864e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<39665x175730 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 3834096 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b485ca1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<9917x175730 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 928119 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3e3c67ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique words: 175730\n",
      "Type of train features: <class 'scipy.sparse._csr.csr_matrix'>\n",
      "Type of train features: <class 'scipy.sparse._csr.csr_matrix'>\n",
      "Shape of input data: (39665, 175730)\n",
      "Shape of input data: (9917, 175730)\n"
     ]
    }
   ],
   "source": [
    "print(\"Total unique words:\", len(vocab.vocabulary_))\n",
    "\n",
    "print(\"Type of train features:\", type(X_train_bow))\n",
    "\n",
    "print(\"Type of train features:\", type(X_test_bow))\n",
    "\n",
    "print(\"Shape of input data:\", X_train_bow.shape)\n",
    "\n",
    "print(\"Shape of input data:\", X_test_bow.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0fe46d72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse._csr.csr_matrix'>\n",
      "48 Bytes\n"
     ]
    }
   ],
   "source": [
    "from sys import getsizeof\n",
    "\n",
    "print(type(X_train_bow))\n",
    "print(getsizeof(X_train_bow), \"Bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58c16fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3e3eb591",
   "metadata": {},
   "source": [
    "from sys import getsizeof\n",
    "\n",
    "print(type(X_train_bow.toarray()))\n",
    "\n",
    "print(getsizeof(X_train_bow.toarray()), \"Bytes\")\n",
    "\n",
    "\n",
    "---------------------------------------------------------------------------\n",
    "MemoryError                               Traceback (most recent call last)\n",
    "Input In [69], in <cell line: 3>()\n",
    "\n",
    "      1 from sys import getsizeof\n",
    "      \n",
    "----> 3 print(type(X_train_bow.toarray()))\n",
    "\n",
    "      4 print(getsizeof(X_train_bow.toarray()), \"Bytes\")\n",
    "\n",
    "File ~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\scipy\\sparse\\_compressed.py:1051, in _cs_matrix.toarray(self, order, out)\n",
    "\n",
    "   1049 if out is None and order is None:\n",
    "   \n",
    "   1050     order = self._swap('cf')[0]\n",
    "   \n",
    "-> 1051 out = self._process_toarray_args(order, out)\n",
    "\n",
    "   1052 if not (out.flags.c_contiguous or out.flags.f_contiguous):\n",
    "   \n",
    "   1053     raise ValueError('Output array must be C or F contiguous')\n",
    "   \n",
    "\n",
    "File ~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\scipy\\sparse\\_base.py:1291, in spmatrix._process_toarray_args(self, order, out)\n",
    "\n",
    "   1289     return out\n",
    "   \n",
    "   1290 else:\n",
    "   \n",
    "-> 1291     return np.zeros(self.shape, dtype=self.dtype, order=order)\n",
    "\n",
    "\n",
    "**MemoryError: Unable to allocate 75.2 GiB for an array with shape (49582, 203561) and data type int64**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f478fef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cb7cc26b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'really': 125331,\n",
       " 'liked': 88528,\n",
       " 'movie': 100985,\n",
       " 'emporers': 47127,\n",
       " 'new': 104767,\n",
       " 'groove': 65264,\n",
       " 'watching': 168207,\n",
       " 'like': 88505,\n",
       " 'coming': 29527,\n",
       " 'home': 71897,\n",
       " 'seeing': 135463,\n",
       " 'wife': 170819,\n",
       " 'relation': 126792,\n",
       " 'llama': 89485,\n",
       " 'seriously': 136995,\n",
       " 'bad': 11206,\n",
       " 'club': 28253,\n",
       " 'dread': 43477,\n",
       " 'super': 149487,\n",
       " 'trooper': 159873,\n",
       " 'supposed': 149909,\n",
       " 'write': 173180,\n",
       " 'line': 88790,\n",
       " 'dont': 42488,\n",
       " 'even': 49692,\n",
       " 'know': 84300,\n",
       " 'else': 46623,\n",
       " 'say': 133042,\n",
       " 'laughed': 86406,\n",
       " 'couple': 32713,\n",
       " 'time': 156315,\n",
       " 'drinking': 43742,\n",
       " 'least': 86941,\n",
       " 'funny': 59763,\n",
       " 'drunk': 44007,\n",
       " 'maybe': 94844,\n",
       " 'regular': 126554,\n",
       " 'cartoon': 23174,\n",
       " 'people': 114859,\n",
       " 'arent': 8046,\n",
       " 'either': 46136,\n",
       " 'way': 168496,\n",
       " 'stick': 146532,\n",
       " 'want': 167554,\n",
       " 'llamathemed': 89486,\n",
       " 'right': 129209,\n",
       " 'decided': 36928,\n",
       " 'watch': 168113,\n",
       " 'noted': 106764,\n",
       " 'scariest': 133336,\n",
       " 'ever': 49788,\n",
       " 'thats': 153732,\n",
       " 'expected': 51002,\n",
       " 'unfortunately': 162710,\n",
       " 'found': 58178,\n",
       " 'didnt': 39489,\n",
       " 'single': 140304,\n",
       " 'scary': 133368,\n",
       " 'moment': 99359,\n",
       " 'im': 75029,\n",
       " 'kind': 83732,\n",
       " 'person': 115565,\n",
       " 'jump': 81872,\n",
       " 'easily': 45191,\n",
       " 'nothing': 106809,\n",
       " 'terrible': 153192,\n",
       " 'clichs': 27853,\n",
       " 'every': 49963,\n",
       " 'jumpmoment': 81886,\n",
       " 'incredibly': 76103,\n",
       " 'obvious': 108021,\n",
       " 'pro': 121075,\n",
       " 'would': 172960,\n",
       " 'music': 102682,\n",
       " 'odd': 108240,\n",
       " 'scene': 133475,\n",
       " 'actually': 1708,\n",
       " 'shot': 138910,\n",
       " 'well': 169177,\n",
       " 'last': 86088,\n",
       " 'open': 110149,\n",
       " 'door': 42580,\n",
       " 'see': 135423,\n",
       " 'tun': 160362,\n",
       " 'reflection': 126339,\n",
       " 'swing': 150754,\n",
       " 'back': 10964,\n",
       " 'ghost': 61989,\n",
       " 'shoulder': 139003,\n",
       " 'overall': 111758,\n",
       " 'added': 1814,\n",
       " 'jhorror': 80912,\n",
       " 'genre': 61502,\n",
       " 'allaround': 4053,\n",
       " 'lacked': 85293,\n",
       " 'creativity': 33515,\n",
       " 'scare': 133281,\n",
       " 'hard': 67686,\n",
       " 'going': 63242,\n",
       " 'lady': 85388,\n",
       " 'shanghai': 137835,\n",
       " 'film': 54725,\n",
       " 'could': 32481,\n",
       " 'without': 171657,\n",
       " 'studio': 148064,\n",
       " 'interference': 77861,\n",
       " 'orson': 110828,\n",
       " 'welles': 169306,\n",
       " 'prime': 120887,\n",
       " 'interest': 77748,\n",
       " 'point': 118192,\n",
       " 'raise': 124236,\n",
       " 'money': 99512,\n",
       " 'theater': 153808,\n",
       " 'indeed': 76152,\n",
       " 'funding': 59655,\n",
       " 'project': 121595,\n",
       " 'drove': 43883,\n",
       " 'seek': 135495,\n",
       " 'acting': 1124,\n",
       " 'job': 81074,\n",
       " 'made': 91870,\n",
       " 'soon': 143248,\n",
       " 'exwife': 51694,\n",
       " 'rita': 129535,\n",
       " 'hayworth': 68477,\n",
       " 'harry': 67991,\n",
       " 'cohn': 28733,\n",
       " 'fearful': 53670,\n",
       " 'ritas': 129541,\n",
       " 'image': 75033,\n",
       " 'held': 69205,\n",
       " 'release': 126863,\n",
       " 'one': 109454,\n",
       " 'yearthe': 174233,\n",
       " 'plot': 117790,\n",
       " 'concern': 30371,\n",
       " 'irish': 78551,\n",
       " 'sailor': 131998,\n",
       " 'michael': 97141,\n",
       " 'ohara': 108852,\n",
       " 'fall': 52400,\n",
       " 'love': 90595,\n",
       " 'stunning': 148204,\n",
       " 'short': 138806,\n",
       " 'blond': 16617,\n",
       " 'hair': 66562,\n",
       " 'husband': 73978,\n",
       " 'known': 84369,\n",
       " 'criminal': 33877,\n",
       " 'attorney': 9739,\n",
       " 'arthur': 8604,\n",
       " 'bannister': 12055,\n",
       " 'everett': 49836,\n",
       " 'sloane': 141460,\n",
       " 'crippled': 33940,\n",
       " 'inside': 77184,\n",
       " 'hire': 71110,\n",
       " 'work': 172375,\n",
       " 'yacht': 173792,\n",
       " 'drawn': 43454,\n",
       " 'deeper': 37139,\n",
       " 'web': 168866,\n",
       " 'murder': 102478,\n",
       " 'deceitthe': 36866,\n",
       " 'move': 100931,\n",
       " 'snail': 142005,\n",
       " 'pace': 112565,\n",
       " 'though': 155438,\n",
       " 'agree': 3128,\n",
       " 'poster': 119379,\n",
       " 'today': 157163,\n",
       " 'criticized': 34029,\n",
       " 'taking': 151467,\n",
       " 'build': 20406,\n",
       " 'still': 146599,\n",
       " 'drag': 43222,\n",
       " 'fun': 59603,\n",
       " 'house': 73042,\n",
       " 'fantastic': 52813,\n",
       " 'wanted': 167560,\n",
       " 'believe': 14111,\n",
       " 'cut': 34956,\n",
       " 'shame': 137775,\n",
       " 'photography': 116265,\n",
       " 'throughout': 155900,\n",
       " 'atmospheric': 9495,\n",
       " 'bold': 17324,\n",
       " 'stylishwelles': 148421,\n",
       " 'excellent': 50397,\n",
       " 'actor': 1452,\n",
       " 'handsome': 67266,\n",
       " 'youth': 174830,\n",
       " 'charismatic': 25208,\n",
       " 'possessing': 119256,\n",
       " 'magnificent': 92204,\n",
       " 'voice': 166758,\n",
       " 'technique': 152439,\n",
       " 'many': 93399,\n",
       " 'almost': 4520,\n",
       " 'doesnt': 41961,\n",
       " 'trust': 160104,\n",
       " 'take': 151410,\n",
       " 'develop': 38889,\n",
       " 'character': 24869,\n",
       " 'instead': 77368,\n",
       " 'relies': 126977,\n",
       " 'external': 51523,\n",
       " 'accent': 647,\n",
       " 'fake': 52338,\n",
       " 'nose': 106644,\n",
       " 'tomorrow': 157575,\n",
       " 'forever': 57671,\n",
       " 'director': 40260,\n",
       " 'get': 61843,\n",
       " 'deeply': 37149,\n",
       " 'felt': 54014,\n",
       " 'performance': 115188,\n",
       " 'contrast': 31431,\n",
       " 'compulsion': 30230,\n",
       " 'show': 139051,\n",
       " 'master': 94286,\n",
       " 'pure': 122903,\n",
       " 'technical': 152416,\n",
       " 'phone': 116180,\n",
       " 'quadruple': 123224,\n",
       " 'duty': 44713,\n",
       " 'star': 145678,\n",
       " 'cowriter': 33005,\n",
       " 'narrator': 103599,\n",
       " 'sporting': 144932,\n",
       " 'completely': 30058,\n",
       " 'unnecessary': 163230,\n",
       " 'looking': 90107,\n",
       " 'intense': 77630,\n",
       " 'fast': 53232,\n",
       " 'characterization': 24955,\n",
       " 'nevertheless': 104747,\n",
       " 'always': 4909,\n",
       " 'compellingthe': 29953,\n",
       " 'supporting': 149892,\n",
       " 'player': 117518,\n",
       " 'including': 75950,\n",
       " 'sloan': 141459,\n",
       " 'glenn': 62759,\n",
       " 'anders': 5728,\n",
       " 'gorgeous': 63965,\n",
       " 'softvoiced': 142620,\n",
       " 'singing': 140291,\n",
       " 'dubbed': 44101,\n",
       " 'anita': 6175,\n",
       " 'elli': 46551,\n",
       " 'usual': 164460,\n",
       " 'complete': 30044,\n",
       " 'goddess': 63061,\n",
       " 'great': 64720,\n",
       " 'screen': 134518,\n",
       " 'presence': 120475,\n",
       " 'sad': 131760,\n",
       " 'life': 88126,\n",
       " 'vibrant': 165692,\n",
       " 'beautyany': 13272,\n",
       " 'directed': 40158,\n",
       " 'worth': 172902,\n",
       " 'exception': 50449,\n",
       " 'leaf': 86866,\n",
       " 'viewer': 166003,\n",
       " 'frustrated': 59347,\n",
       " 'ambersons': 5108,\n",
       " 'within': 171635,\n",
       " 'system': 151136,\n",
       " 'artist': 8653,\n",
       " 'given': 62586,\n",
       " 'freer': 58768,\n",
       " 'reign': 126632,\n",
       " 'wasnt': 167980,\n",
       " 'strange': 147499,\n",
       " 'dichotomy': 39376,\n",
       " 'needed': 104216,\n",
       " 'freedom': 58710,\n",
       " 'evidenced': 50108,\n",
       " 'later': 86175,\n",
       " 'structure': 147936,\n",
       " 'ala': 3582,\n",
       " 'couldnt': 32494,\n",
       " 'scifi': 134200,\n",
       " 'adventure': 2212,\n",
       " 'best': 14745,\n",
       " 'mean': 95437,\n",
       " 'worst': 172860,\n",
       " 'statement': 146007,\n",
       " 'comical': 29480,\n",
       " 'bizarre': 15962,\n",
       " 'pink': 116831,\n",
       " 'tinting': 156869,\n",
       " 'unusual': 163801,\n",
       " 'special': 144094,\n",
       " 'effect': 45714,\n",
       " 'make': 92443,\n",
       " 'favorite': 53542,\n",
       " 'late': 86136,\n",
       " 'space': 143794,\n",
       " 'explorer': 51324,\n",
       " 'planet': 117322,\n",
       " 'mar': 93455,\n",
       " 'fight': 54575,\n",
       " 'giant': 62096,\n",
       " 'amoebalike': 5406,\n",
       " 'monster': 99760,\n",
       " 'creature': 33532,\n",
       " 'pretty': 120693,\n",
       " 'coolthe': 31758,\n",
       " 'cast': 23421,\n",
       " 'includes': 75945,\n",
       " 'le': 86796,\n",
       " 'tremayne': 159404,\n",
       " 'naura': 103852,\n",
       " 'hayden': 68438,\n",
       " 'gerald': 61706,\n",
       " 'mohr': 99251,\n",
       " 'jack': 79943,\n",
       " 'kruschen': 84940,\n",
       " 'comfy': 29475,\n",
       " 'enjoy': 47883,\n",
       " 'feel': 53833,\n",
       " 'nod': 105648,\n",
       " 'adding': 1852,\n",
       " 'list': 89094,\n",
       " 'cult': 34620,\n",
       " 'classic': 27467,\n",
       " 'miss': 98618,\n",
       " 'around': 8379,\n",
       " 'animator': 6140,\n",
       " 'bluth': 16956,\n",
       " 'output': 111552,\n",
       " 'company': 29861,\n",
       " 'disney': 41116,\n",
       " 'churning': 26803,\n",
       " 'defected': 37229,\n",
       " 'mouse': 100867,\n",
       " 'form': 57848,\n",
       " 'first': 55957,\n",
       " 'production': 121347,\n",
       " 'secret': 135305,\n",
       " 'nimh': 105403,\n",
       " 'brilliant': 19382,\n",
       " 'feature': 53732,\n",
       " 'hold': 71636,\n",
       " 'day': 36154,\n",
       " 'followed': 57210,\n",
       " 'american': 5233,\n",
       " 'tail': 151351,\n",
       " 'land': 85699,\n",
       " 'involvement': 78439,\n",
       " 'steven': 146473,\n",
       " 'spielberg': 144411,\n",
       " 'commercially': 29686,\n",
       " 'successful': 148855,\n",
       " 'although': 4836,\n",
       " 'none': 105974,\n",
       " 'two': 160954,\n",
       " 'dark': 35772,\n",
       " 'adult': 2140,\n",
       " 'appeal': 7483,\n",
       " 'charming': 25275,\n",
       " 'enjoyable': 47886,\n",
       " 'child': 25982,\n",
       " 'grownup': 65417,\n",
       " 'long': 89897,\n",
       " 'major': 92425,\n",
       " 'misfire': 98482,\n",
       " 'dog': 42009,\n",
       " 'go': 62954,\n",
       " 'heaven': 68934,\n",
       " 'critic': 34004,\n",
       " 'especially': 49158,\n",
       " 'harsh': 68002,\n",
       " 'matter': 94630,\n",
       " 'werent': 169715,\n",
       " 'helped': 69346,\n",
       " 'fact': 52056,\n",
       " 'opened': 110153,\n",
       " 'alongside': 4640,\n",
       " 'little': 89237,\n",
       " 'mermaidconsidering': 96646,\n",
       " 'friendlysounding': 59010,\n",
       " 'title': 156973,\n",
       " 'expect': 50969,\n",
       " 'pleasant': 117646,\n",
       " 'family': 52534,\n",
       " 'fare': 52962,\n",
       " 'provides': 122099,\n",
       " 'surprisingly': 150183,\n",
       " 'story': 147095,\n",
       " 'involving': 78446,\n",
       " 'gambling': 60448,\n",
       " 'deceit': 36862,\n",
       " 'crime': 33812,\n",
       " 'mistreatment': 98825,\n",
       " 'problem': 121116,\n",
       " 'animated': 6101,\n",
       " 'per': 115015,\n",
       " 'call': 21692,\n",
       " 'question': 123521,\n",
       " 'whether': 170220,\n",
       " 'hand': 67128,\n",
       " 'find': 55657,\n",
       " 'much': 101973,\n",
       " 'identity': 74576,\n",
       " 'crisisset': 33954,\n",
       " 'dreary': 43623,\n",
       " 'junkyard': 81974,\n",
       " 'orleans': 110780,\n",
       " 'start': 145876,\n",
       " 'charlie': 25239,\n",
       " 'barkin': 12285,\n",
       " 'roughandtumble': 130865,\n",
       " 'german': 61738,\n",
       " 'shepherd': 138265,\n",
       " 'run': 131344,\n",
       " 'car': 22538,\n",
       " 'courtesy': 32830,\n",
       " 'former': 57893,\n",
       " 'casino': 23364,\n",
       " 'partner': 113733,\n",
       " 'nasty': 103666,\n",
       " 'cigarpuffing': 26863,\n",
       " 'pitbull': 117000,\n",
       " 'carface': 22832,\n",
       " 'albeit': 3658,\n",
       " 'default': 37203,\n",
       " 'whippet': 170330,\n",
       " 'angel': 5910,\n",
       " 'annabelle': 6218,\n",
       " 'tell': 152802,\n",
       " 'unlike': 163110,\n",
       " 'usually': 164467,\n",
       " 'loyal': 90971,\n",
       " 'represents': 127619,\n",
       " 'confused': 30708,\n",
       " 'nature': 103791,\n",
       " 'since': 140196,\n",
       " 'aside': 8923,\n",
       " 'presented': 120503,\n",
       " 'anything': 7067,\n",
       " 'butupon': 21200,\n",
       " 'realizing': 125320,\n",
       " 'he': 68532,\n",
       " 'murdered': 102490,\n",
       " 'steal': 146189,\n",
       " 'earth': 45113,\n",
       " 'reluctant': 127039,\n",
       " 'help': 69343,\n",
       " 'dachshund': 35208,\n",
       " 'pal': 112876,\n",
       " 'itchy': 79253,\n",
       " 'rescue': 127778,\n",
       " 'carfaces': 22833,\n",
       " 'prize': 121061,\n",
       " 'annemarie': 6238,\n",
       " 'human': 73561,\n",
       " 'girl': 62368,\n",
       " 'talk': 151589,\n",
       " 'animal': 6064,\n",
       " 'order': 110521,\n",
       " 'predict': 120094,\n",
       " 'win': 171151,\n",
       " 'rat': 124717,\n",
       " 'race': 123866,\n",
       " 'claim': 27327,\n",
       " 'cutie': 35009,\n",
       " 'reality': 125256,\n",
       " 'using': 164410,\n",
       " 'skill': 140848,\n",
       " 'fortune': 58074,\n",
       " 'elaborate': 46260,\n",
       " 'bring': 19461,\n",
       " 'refuse': 126420,\n",
       " 'admit': 2033,\n",
       " 'grow': 65402,\n",
       " 'annemariethe': 6240,\n",
       " 'concept': 30338,\n",
       " 'isnt': 78913,\n",
       " 'problematic': 121120,\n",
       " 'execution': 50670,\n",
       " 'flamboyant': 56270,\n",
       " 'musical': 102685,\n",
       " 'alligator': 4212,\n",
       " 'appears': 7546,\n",
       " 'threequarters': 155694,\n",
       " 'vocal': 166725,\n",
       " 'pipe': 116915,\n",
       " 'ken': 82962,\n",
       " 'page': 112712,\n",
       " 'emerge': 46900,\n",
       " 'likable': 88491,\n",
       " 'frankly': 58534,\n",
       " 'caring': 22871,\n",
       " 'also': 4747,\n",
       " 'applies': 7623,\n",
       " 'trying': 160180,\n",
       " 'antihero': 6711,\n",
       " 'script': 134724,\n",
       " 'composed': 30167,\n",
       " 'ten': 152915,\n",
       " 'writer': 173191,\n",
       " 'succeeds': 148828,\n",
       " 'rendering': 127300,\n",
       " 'unlovable': 163147,\n",
       " 'audience': 9832,\n",
       " 'empathy': 47076,\n",
       " 'worse': 172776,\n",
       " 'redemption': 126074,\n",
       " 'end': 47278,\n",
       " 'come': 29232,\n",
       " 'across': 1069,\n",
       " 'convincing': 31619,\n",
       " 'damaging': 35405,\n",
       " 'disappointingly': 40595,\n",
       " 'uncharismatic': 161910,\n",
       " 'burt': 20871,\n",
       " 'reynolds': 128785,\n",
       " 'besides': 14722,\n",
       " 'lack': 85287,\n",
       " 'endearing': 47330,\n",
       " 'lead': 86804,\n",
       " 'slowlypaced': 141579,\n",
       " 'place': 117120,\n",
       " 'habit': 66323,\n",
       " 'throwing': 155977,\n",
       " 'extra': 51553,\n",
       " 'serve': 137081,\n",
       " 'purpose': 122960,\n",
       " 'pad': 112666,\n",
       " 'running': 131383,\n",
       " 'aforementioned': 2516,\n",
       " 'resides': 127870,\n",
       " 'danky': 35666,\n",
       " 'sewer': 137337,\n",
       " 'infested': 76633,\n",
       " 'native': 103738,\n",
       " 'seems': 135534,\n",
       " 'thrown': 155980,\n",
       " 'nowhere': 107267,\n",
       " 'try': 160166,\n",
       " 'generosity': 61394,\n",
       " 'feeding': 53830,\n",
       " 'pack': 112627,\n",
       " 'pastelcolored': 113964,\n",
       " 'pup': 122840,\n",
       " 'pizza': 117102,\n",
       " 'whole': 170545,\n",
       " 'screenplay': 134598,\n",
       " 'rough': 130861,\n",
       " 'draft': 43212,\n",
       " 'bit': 15862,\n",
       " 'polish': 118494,\n",
       " 'tighter': 156234,\n",
       " 'impactful': 75331,\n",
       " 'storymatters': 147248,\n",
       " 'lackluster': 85307,\n",
       " 'number': 107515,\n",
       " 'strouse': 147927,\n",
       " 'tj': 157046,\n",
       " 'kuenster': 85002,\n",
       " 'annemaries': 6239,\n",
       " 'song': 143091,\n",
       " 'gator': 60988,\n",
       " 'ballad': 11735,\n",
       " 'good': 63475,\n",
       " 'latter': 86319,\n",
       " 'particular': 113692,\n",
       " 'benefit': 14377,\n",
       " 'mellifluous': 96080,\n",
       " 'uneven': 162551,\n",
       " 'mentioned': 96444,\n",
       " 'stiff': 146558,\n",
       " 'lifeless': 88246,\n",
       " 'detracts': 38843,\n",
       " 'already': 4698,\n",
       " 'unlikeable': 163111,\n",
       " 'fiery': 54532,\n",
       " 'confession': 30609,\n",
       " 'true': 160003,\n",
       " 'intention': 77662,\n",
       " 'toward': 158444,\n",
       " 'dom': 42251,\n",
       " 'deluise': 37703,\n",
       " 'better': 14912,\n",
       " 'role': 130123,\n",
       " 'notably': 106705,\n",
       " 'tiger': 156216,\n",
       " 'jeremy': 80697,\n",
       " 'awesome': 10569,\n",
       " 'small': 141695,\n",
       " 'part': 113615,\n",
       " 'contribution': 31450,\n",
       " 'unremarkable': 163475,\n",
       " 'similarly': 140049,\n",
       " 'wasted': 168040,\n",
       " 'loni': 90060,\n",
       " 'anderson': 5732,\n",
       " 'collie': 29005,\n",
       " 'sired': 140431,\n",
       " 'litter': 89230,\n",
       " 'melba': 96032,\n",
       " 'moore': 100026,\n",
       " 'charles': 25227,\n",
       " 'nelson': 104443,\n",
       " 'reilly': 126645,\n",
       " 'judith': 81780,\n",
       " 'barsi': 12416,\n",
       " 'probably': 121095,\n",
       " 'truly': 160073,\n",
       " 'memorable': 96193,\n",
       " 'partially': 113664,\n",
       " 'sole': 142722,\n",
       " 'legitimately': 87272,\n",
       " 'depressing': 38177,\n",
       " 'joyless': 81640,\n",
       " 'showbarsi': 139064,\n",
       " 'real': 125169,\n",
       " 'positive': 119219,\n",
       " 'animation': 6111,\n",
       " 'technically': 152419,\n",
       " 'imaginative': 75095,\n",
       " 'visuals': 166609,\n",
       " 'bluths': 16957,\n",
       " 'team': 152310,\n",
       " 'standard': 145570,\n",
       " 'particularly': 113701,\n",
       " 'frightening': 59125,\n",
       " 'nightmare': 105273,\n",
       " 'ending': 47401,\n",
       " 'underworld': 162405,\n",
       " 'ruled': 131277,\n",
       " 'gargantuan': 60812,\n",
       " 'satanic': 132734,\n",
       " 'caninedemon': 22205,\n",
       " 'triumph': 159766,\n",
       " 'storytellingon': 147321,\n",
       " 'however': 73198,\n",
       " 'can': 22056,\n",
       " 'not': 106701,\n",
       " 'recommend': 125870,\n",
       " 'entertainment': 48330,\n",
       " 'recognize': 125838,\n",
       " 'fan': 52644,\n",
       " 'climax': 27925,\n",
       " 'admittingly': 2046,\n",
       " 'provide': 122090,\n",
       " 'energy': 47693,\n",
       " 'moving': 101753,\n",
       " 'conclusion': 30425,\n",
       " 'package': 112628,\n",
       " 'league': 86871,\n",
       " 'effort': 45862,\n",
       " 'buff': 20325,\n",
       " 'marvel': 94048,\n",
       " 'lush': 91369,\n",
       " 'artistry': 8674,\n",
       " 'leave': 87010,\n",
       " 'taste': 152049,\n",
       " 'mouth': 100889,\n",
       " 'perv': 115736,\n",
       " 'lesbian': 87565,\n",
       " 'stuffthe': 148159,\n",
       " 'red': 126037,\n",
       " 'wig': 170883,\n",
       " 'lip': 89004,\n",
       " 'silicone': 139918,\n",
       " 'shes': 138332,\n",
       " 'lame': 85590,\n",
       " 'insecure': 77159,\n",
       " 'surferguy': 150054,\n",
       " 'dressing': 43674,\n",
       " 'slutty': 141673,\n",
       " 'weird': 169086,\n",
       " 'definitely': 37326,\n",
       " 'unfashionable': 162613,\n",
       " 'explain': 51204,\n",
       " 'pa': 112547,\n",
       " 'man': 92830,\n",
       " 'oh': 108845,\n",
       " 'poor': 118773,\n",
       " 'dumb': 44394,\n",
       " 'forgot': 57803,\n",
       " 'invention': 78295,\n",
       " 'lousy': 90563,\n",
       " 'actress': 1631,\n",
       " 'plus': 118044,\n",
       " 'waif': 167219,\n",
       " 'look': 90073,\n",
       " 'outthis': 111677,\n",
       " 'melrose': 96130,\n",
       " 'playssurprise': 117607,\n",
       " 'blondshe': 16637,\n",
       " 'think': 154938,\n",
       " 'guy': 66096,\n",
       " 'ewww': 50235,\n",
       " 'guess': 65634,\n",
       " 'sort': 143434,\n",
       " 'psycho': 122384,\n",
       " 'toy': 158542,\n",
       " 'maker': 92476,\n",
       " 'named': 103386,\n",
       " 'joe': 81204,\n",
       " 'petto': 115885,\n",
       " 'living': 89425,\n",
       " 'evil': 50129,\n",
       " 'kill': 83508,\n",
       " 'luck': 91079,\n",
       " 'simply': 140147,\n",
       " 'mutant': 102897,\n",
       " 'robot': 129834,\n",
       " 'son': 143062,\n",
       " 'pino': 116864,\n",
       " 'used': 164328,\n",
       " 'liveeasily': 89321,\n",
       " 'hopefully': 72328,\n",
       " 'presumably': 120618,\n",
       " 'semi': 136186,\n",
       " 'series': 136900,\n",
       " 'previous': 120756,\n",
       " 'soft': 142578,\n",
       " 'core': 31995,\n",
       " 'porn': 119012,\n",
       " 'sex': 137346,\n",
       " 'nudity': 107449,\n",
       " 'low': 90841,\n",
       " 'rent': 127358,\n",
       " 'hybrid': 74103,\n",
       " 'halloween': 66928,\n",
       " 'iii': 74804,\n",
       " 'puppet': 122850,\n",
       " 'doll': 42198,\n",
       " 'supposedly': 149911,\n",
       " 'started': 145889,\n",
       " 'sixth': 140674,\n",
       " 'chapter': 24847,\n",
       " 'abandoned': 96,\n",
       " 'never': 104718,\n",
       " 'completed': 30046,\n",
       " 'hope': 72314,\n",
       " 'stay': 146144,\n",
       " 'oddly': 108263,\n",
       " 'lit': 89170,\n",
       " 'men': 96273,\n",
       " 'woman': 171904,\n",
       " 'beating': 13143,\n",
       " 'crap': 33194,\n",
       " 'boxer': 18460,\n",
       " 'gay': 61060,\n",
       " 'filmafter': 54740,\n",
       " 'badly': 11331,\n",
       " 'bruised': 19948,\n",
       " 'beat': 13127,\n",
       " 'hell': 69235,\n",
       " 'methis': 96961,\n",
       " 'meant': 95538,\n",
       " 'gawk': 61053,\n",
       " 'horror': 72546,\n",
       " 'wonder': 172039,\n",
       " 'lot': 90416,\n",
       " 'airplane': 3426,\n",
       " 'crash': 33318,\n",
       " 'train': 158769,\n",
       " 'wreckif': 173113,\n",
       " 'mediocre': 95744,\n",
       " 'ita': 79106,\n",
       " 'warning': 167761,\n",
       " 'please': 117658,\n",
       " 'eat': 45287,\n",
       " 'beforehand': 13621,\n",
       " 'might': 97439,\n",
       " 'puke': 122630,\n",
       " 'sam': 132219,\n",
       " 'thomas': 155357,\n",
       " 'cavanagh': 23914,\n",
       " 'gray': 64665,\n",
       " 'heather': 68918,\n",
       " 'graham': 64356,\n",
       " 'devoted': 39051,\n",
       " 'sibling': 139526,\n",
       " 'share': 137905,\n",
       " 'apartment': 7287,\n",
       " 'thing': 154781,\n",
       " 'ballroom': 11795,\n",
       " 'dancing': 35543,\n",
       " 'surprise': 150118,\n",
       " 'attractive': 9754,\n",
       " 'bridget': 19291,\n",
       " 'moynahan': 101790,\n",
       " 'historically': 71195,\n",
       " 'heterosexual': 70150,\n",
       " 'feelingsgray': 53866,\n",
       " 'prof': 121419,\n",
       " 'blandest': 16271,\n",
       " 'seen': 135549,\n",
       " 'dull': 44327,\n",
       " 'predictable': 120100,\n",
       " 'unfunny': 162756,\n",
       " 'poorly': 118797,\n",
       " 'acted': 1090,\n",
       " 'written': 173317,\n",
       " 'everything': 50024,\n",
       " 'cheesy': 25640,\n",
       " 'romantic': 130412,\n",
       " 'comedy': 29287,\n",
       " 'twist': 160891,\n",
       " 'sue': 149044,\n",
       " 'kramer': 84786,\n",
       " 'tried': 159588,\n",
       " 'half': 66657,\n",
       " 'cute': 34968,\n",
       " 'stuff': 148117,\n",
       " 'second': 135210,\n",
       " 'serious': 136985,\n",
       " 'actual': 1700,\n",
       " 'acceptance': 700,\n",
       " 'failed': 52194,\n",
       " 'miserably': 98453,\n",
       " 'largely': 85961,\n",
       " 'able': 247,\n",
       " 'took': 157754,\n",
       " 'awkward': 10675,\n",
       " 'tone': 157598,\n",
       " 'got': 64070,\n",
       " 'handled': 67207,\n",
       " 'emotion': 47003,\n",
       " 'phonyi': 116220,\n",
       " 'enjoyed': 47932,\n",
       " 'relationship': 126796,\n",
       " 'authentic': 10092,\n",
       " 'brother': 19794,\n",
       " 'sister': 140478,\n",
       " 'weak': 168745,\n",
       " 'appear': 7504,\n",
       " 'close': 28076,\n",
       " 'natural': 103766,\n",
       " 'tom': 157492,\n",
       " 'unnatural': 163217,\n",
       " 'married': 93891,\n",
       " 'knowing': 84335,\n",
       " 'week': 168935,\n",
       " 'excitement': 50513,\n",
       " 'talked': 151599,\n",
       " 'getting': 61901,\n",
       " 'vega': 165171,\n",
       " 'manner': 93197,\n",
       " 'asking': 8961,\n",
       " 'waiter': 167252,\n",
       " 'involved': 78411,\n",
       " 'unmotivated': 163196,\n",
       " 'charactersthe': 25101,\n",
       " 'mostly': 100571,\n",
       " 'surprising': 150180,\n",
       " 'decent': 36885,\n",
       " 'gave': 61039,\n",
       " 'costars': 32340,\n",
       " 'dud': 44188,\n",
       " 'ringed': 129381,\n",
       " 'false': 52441,\n",
       " 'level': 87797,\n",
       " 'seemed': 135516,\n",
       " 'reading': 125119,\n",
       " 'wooden': 172161,\n",
       " 'showed': 139098,\n",
       " 'nearly': 104069,\n",
       " 'chemistry': 25698,\n",
       " 'non': 105828,\n",
       " 'existent': 50833,\n",
       " 'damaged': 35401,\n",
       " 'phony': 116217,\n",
       " 'rely': 127043,\n",
       " 'molly': 99338,\n",
       " 'shannon': 137860,\n",
       " 'annoying': 6309,\n",
       " 'sissy': 140473,\n",
       " 'spacek': 143828,\n",
       " 'finally': 55628,\n",
       " 'alan': 3606,\n",
       " 'cumming': 34709,\n",
       " 'embarrassing': 46821,\n",
       " 'rating': 124776,\n",
       " 'awful': 10598,\n",
       " 'full': 59511,\n",
       " 'cliche': 27831,\n",
       " 'perplexing': 115504,\n",
       " 'atrotious': 9562,\n",
       " 'wrote': 173442,\n",
       " 'larry': 86021,\n",
       " 'flint': 56721,\n",
       " 'moon': 99983,\n",
       " 'garbage': 60712,\n",
       " 'top': 157907,\n",
       " 'alltime': 4393,\n",
       " 'realize': 125308,\n",
       " 'enough': 48038,\n",
       " 'let': 87715,\n",
       " 'alone': 4566,\n",
       " 'sequel': 136710,\n",
       " 'amazing': 5057,\n",
       " 'piece': 116575,\n",
       " 'trash': 159099,\n",
       " 'shown': 139169,\n",
       " 'released': 126870,\n",
       " 'example': 50301,\n",
       " 'fine': 55678,\n",
       " 'storytelling': 147314,\n",
       " 'superb': 149495,\n",
       " 'inspiring': 77317,\n",
       " 'overly': 112061,\n",
       " 'manipulative': 93123,\n",
       " 'tad': 151282,\n",
       " 'considering': 31018,\n",
       " 'hollywood': 71754,\n",
       " 'restraint': 128135,\n",
       " 'explosion': 51328,\n",
       " 'opportunity': 110348,\n",
       " 'suspenseful': 150363,\n",
       " 'action': 1257,\n",
       " 'thus': 156093,\n",
       " 'focus': 57071,\n",
       " 'extraordinary': 51579,\n",
       " 'ordinary': 110552,\n",
       " 'done': 42360,\n",
       " 'thoroughly': 155410,\n",
       " 'incoherent': 75964,\n",
       " 'rambling': 124327,\n",
       " 'oneand': 109466,\n",
       " 'damned': 35452,\n",
       " 'modern': 99151,\n",
       " 'ridiculous': 129093,\n",
       " 'period': 115366,\n",
       " 'st': 145325,\n",
       " 'century': 24262,\n",
       " 'style': 148367,\n",
       " 'predominate': 120150,\n",
       " 'yawn': 173979,\n",
       " 'manufactured': 93368,\n",
       " 'belaboured': 13981,\n",
       " 'joke': 81323,\n",
       " 'secondary': 135214,\n",
       " 'juvenile': 82108,\n",
       " 'normally': 106554,\n",
       " 'sweep': 150648,\n",
       " 'parodying': 113568,\n",
       " 'original': 110671,\n",
       " 'de': 36394,\n",
       " 'ville': 166267,\n",
       " 'sunset': 149459,\n",
       " 'boulevard': 18314,\n",
       " 'pointless': 118246,\n",
       " 'basic': 12545,\n",
       " 'instinct': 77426,\n",
       " 'characterisation': 24938,\n",
       " 'acceptable': 689,\n",
       " 'scratch': 134456,\n",
       " 'african': 2544,\n",
       " 'created': 33465,\n",
       " 'rhythm': 128875,\n",
       " 'jawbone': 80417,\n",
       " 'virgin': 166443,\n",
       " 'islander': 78854,\n",
       " 'welded': 169162,\n",
       " 'oil': 108942,\n",
       " 'drum': 43988,\n",
       " 'ear': 45016,\n",
       " 'pleasing': 117702,\n",
       " 'steel': 146232,\n",
       " 'band': 11909,\n",
       " 'urban': 164183,\n",
       " 'dj': 41658,\n",
       " 'itch': 79241,\n",
       " 'pursuit': 123009,\n",
       " 'method': 96962,\n",
       " 'creative': 33503,\n",
       " 'expression': 51392,\n",
       " 'wholly': 170582,\n",
       " 'unnarrated': 163214,\n",
       " 'documentary': 41836,\n",
       " 'heart': 68770,\n",
       " 'hiphoprap': 71056,\n",
       " 'movement': 100953,\n",
       " 'explore': 51319,\n",
       " 'genesis': 61408,\n",
       " 'turntablism': 160558,\n",
       " 'art': 8555,\n",
       " 'scratching': 134466,\n",
       " 'vinyl': 166351,\n",
       " 'ultimate': 161492,\n",
       " 'djmc': 41673,\n",
       " 'contempo': 31226,\n",
       " 'reveals': 128470,\n",
       " 'intelligent': 77596,\n",
       " 'articulate': 8619,\n",
       " 'scratcher': 134460,\n",
       " 'startlingly': 145933,\n",
       " 'unique': 162986,\n",
       " ...}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32625e00",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "\n",
    "\n",
    "Logistic Regression is a statistical model used for binary classification tasks where the goal is to predict the probability of an event occurring. It works by fitting a logistic function to the input data, which maps the input to a probability value between 0 and 1. The logistic function is then used to make predictions by applying a threshold to the probability value, classifying the input as either one of the two possible classes. Logistic Regression is widely used in various fields such as finance, healthcare, and marketing, and can be implemented using various optimization techniques such as gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9ff1e72a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train_bow, y_train_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "aabdc493",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = classifier.predict(X_test_bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7b7cdd",
   "metadata": {},
   "source": [
    "**accuracy_score** is a function used to evaluate the performance of a classification model by computing the proportion of correct predictions made by the model over the total number of predictions. It is a simple and commonly used metric for evaluating the performance of a model.\n",
    "\n",
    "\n",
    "**classification_report** is a function used to generate a summary report of the classification performance of a model. It includes various metrics such as precision, recall, and F1-score for each class, as well as the overall accuracy of the model. It is a useful tool for gaining insight into the strengths and weaknesses of a model's classification performance, and can be used to compare the performance of different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7d3cd509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8793990117979228\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.87      0.88      4939\n",
      "           1       0.87      0.89      0.88      4978\n",
      "\n",
      "    accuracy                           0.88      9917\n",
      "   macro avg       0.88      0.88      0.88      9917\n",
      "weighted avg       0.88      0.88      0.88      9917\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "print(accuracy_score(y_test_bow, y_test_pred))\n",
    "\n",
    "print(classification_report(y_test_bow, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f29a15",
   "metadata": {},
   "source": [
    "## DecisionTreeClassifier\n",
    "\n",
    "DecisionTreeClassifier is a machine learning algorithm used for classification tasks. It works by constructing a decision tree that recursively splits the input data based on the most important features until the data can be classified into distinct classes. The splitting criteria is determined by maximizing the information gain or minimizing the impurity of the resulting splits. The resulting decision tree can be used to make predictions for new input data by traversing the tree from the root to a leaf node corresponding to the predicted class. DecisionTreeClassifier is widely used in various fields such as finance, healthcare, and marketing, and can be used for both binary and multi-class classification tasks. However, it is prone to overfitting and may require regularization techniques such as pruning to improve generalization performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "45375759",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "classifier = DecisionTreeClassifier()\n",
    "classifier.fit(X_train_bow, y_train_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "73cfa4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = classifier.predict(X_test_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2be588cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7104971261470203\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.71      0.71      4939\n",
      "           1       0.71      0.71      0.71      4978\n",
      "\n",
      "    accuracy                           0.71      9917\n",
      "   macro avg       0.71      0.71      0.71      9917\n",
      "weighted avg       0.71      0.71      0.71      9917\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "print(accuracy_score(y_test_bow, y_test_pred))\n",
    "\n",
    "print(classification_report(y_test_bow, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a73870b",
   "metadata": {},
   "source": [
    "## RandomForestClassifier\n",
    "\n",
    "RandomForestClassifier is a machine learning algorithm used for classification tasks. It works by constructing a large number of decision trees (known as an ensemble) and aggregating the results of each tree to make a final prediction. Each tree in the ensemble is trained on a randomly selected subset of the input data and a randomly selected subset of the features, which helps to reduce overfitting and improve generalization performance. The final prediction is determined by a majority vote of the individual tree predictions. RandomForestClassifier is widely used in various fields such as finance, healthcare, and marketing, and is known for its high accuracy and robustness to noisy data. However, it may require more computational resources than other classification algorithms due to its large ensemble of decision trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "366a0a44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier()\n",
    "classifier.fit(X_train_bow, y_train_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "adc97863",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = classifier.predict(X_test_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4e4b3022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8465261671876576\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.85      0.85      4939\n",
      "           1       0.85      0.85      0.85      4978\n",
      "\n",
      "    accuracy                           0.85      9917\n",
      "   macro avg       0.85      0.85      0.85      9917\n",
      "weighted avg       0.85      0.85      0.85      9917\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "print(accuracy_score(y_test_bow, y_test_pred))\n",
    "\n",
    "print(classification_report(y_test_bow, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2716d670",
   "metadata": {},
   "source": [
    "## MultinomialNB (Naive Bayes)\n",
    "\n",
    "MultinomialNB (Naive Bayes) is a machine learning algorithm used for classification tasks, particularly in natural language processing applications. It is based on the Bayes theorem and assumes that the features are conditionally independent given the class label. MultinomialNB is commonly used for text classification tasks, such as sentiment analysis and spam filtering. It works by computing the probability of each class given the input data and selecting the class with the highest probability as the predicted class. The algorithm models the probability distribution of the input features using a multinomial distribution, which assumes that the input features are counts of the frequency of occurrence of each term in a document or corpus. MultinomialNB is known for its simplicity, speed, and good performance in many text classification tasks, but may not be the best choice for data with complex dependencies between features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e57ab415",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(X_train_bow, y_train_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "efd6232d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = classifier.predict(X_test_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "408202c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.855803166280125\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.87      0.86      4939\n",
      "           1       0.87      0.84      0.85      4978\n",
      "\n",
      "    accuracy                           0.86      9917\n",
      "   macro avg       0.86      0.86      0.86      9917\n",
      "weighted avg       0.86      0.86      0.86      9917\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "print(accuracy_score(y_test_bow, y_test_pred))\n",
    "\n",
    "print(classification_report(y_test_bow, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a111e9",
   "metadata": {},
   "source": [
    "## BernoulliNB (Naive Bayes)\n",
    "\n",
    "BernoulliNB (Naive Bayes) is a machine learning algorithm used for classification tasks. It is similar to GaussianNB but is designed for binary or boolean features, where each feature takes only two values, 0 or 1. BernoulliNB works by computing the probability of each class given the input data and selecting the class with the highest probability as the predicted class. The algorithm models the probability distribution of the input features using a Bernoulli distribution, which assumes that each feature is a binary random variable with a certain probability of occurrence. BernoulliNB is known for its simplicity, speed, and good performance in many classification tasks, especially when the input features are binary or sparse. However, it may not perform well in cases where the features are highly correlated or have complex dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "be7a905f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "05a2c0b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-10 {color: black;background-color: white;}#sk-container-id-10 pre{padding: 0;}#sk-container-id-10 div.sk-toggleable {background-color: white;}#sk-container-id-10 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-10 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-10 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-10 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-10 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-10 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-10 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-10 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-10 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-10 div.sk-item {position: relative;z-index: 1;}#sk-container-id-10 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-10 div.sk-item::before, #sk-container-id-10 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-10 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-10 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-10 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-10 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-10 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-10 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-10 div.sk-label-container {text-align: center;}#sk-container-id-10 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-10 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BernoulliNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" checked><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BernoulliNB</label><div class=\"sk-toggleable__content\"><pre>BernoulliNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "BernoulliNB()"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = BernoulliNB()\n",
    "classifier.fit(X_train_bow, y_train_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "2144378a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = classifier.predict(X_test_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "36b98ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8541897751336089\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.87      0.86      4939\n",
      "           1       0.87      0.83      0.85      4978\n",
      "\n",
      "    accuracy                           0.85      9917\n",
      "   macro avg       0.85      0.85      0.85      9917\n",
      "weighted avg       0.85      0.85      0.85      9917\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "print(accuracy_score(y_test_bow, y_test_pred))\n",
    "\n",
    "print(classification_report(y_test_bow, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5138d3",
   "metadata": {},
   "source": [
    "## SVC (Support Vector Machine)\n",
    "\n",
    "\n",
    "SVC (Support Vector Machine) is a machine learning algorithm used for classification tasks. It works by finding the hyperplane that maximally separates the input data into distinct classes. In cases where the data is not linearly separable, SVC can use a kernel trick to transform the input data into a higher-dimensional feature space, where it is more likely to be linearly separable. SVC tries to find a margin that separates the input data with the maximum possible distance between the classes. The points closest to the margin are called support vectors and are used to define the hyperplane. SVC is widely used in various fields such as finance, healthcare, and marketing, and is known for its ability to handle high-dimensional data and non-linearly separable data. However, SVC can be sensitive to the choice of kernel function and may require careful tuning of hyperparameters to achieve good performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9afbf875",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "classifier = SVC()\n",
    "classifier.fit(X_train_bow, y_train_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "35c260f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = classifier.predict(X_test_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3543e5cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8760713925582333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.85      0.87      4939\n",
      "           1       0.86      0.90      0.88      4978\n",
      "\n",
      "    accuracy                           0.88      9917\n",
      "   macro avg       0.88      0.88      0.88      9917\n",
      "weighted avg       0.88      0.88      0.88      9917\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "print(accuracy_score(y_test_bow, y_test_pred))\n",
    "\n",
    "print(classification_report(y_test_bow, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7236bb3c",
   "metadata": {},
   "source": [
    "## KNeighborsClassifier\n",
    "\n",
    "KNeighborsClassifier is a machine learning algorithm used for classification tasks. It works by finding the k-nearest neighbors to the input data point in the feature space and classifying the input data based on the most common class among its k-nearest neighbors. The algorithm uses a distance metric, such as Euclidean or Manhattan distance, to measure the distance between input data points and the training data points. KNeighborsClassifier is a simple and effective algorithm, especially for low-dimensional data, and can handle multi-class classification tasks. However, the algorithm can be sensitive to the choice of k and the distance metric used, and can be computationally expensive for large datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a7703155",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifier = KNeighborsClassifier()\n",
    "classifier.fit(X_train_bow, y_train_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4876fc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = classifier.predict(X_test_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0310a514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.609660179489765\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.58      0.60      4939\n",
      "           1       0.61      0.64      0.62      4978\n",
      "\n",
      "    accuracy                           0.61      9917\n",
      "   macro avg       0.61      0.61      0.61      9917\n",
      "weighted avg       0.61      0.61      0.61      9917\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "print(accuracy_score(y_test_bow, y_test_pred))\n",
    "\n",
    "print(classification_report(y_test_bow, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb29bbee",
   "metadata": {},
   "source": [
    "## GradientBoostingClassifier\n",
    "\n",
    "GradientBoostingClassifier is a machine learning algorithm used for classification tasks. It is a type of boosting algorithm that works by iteratively adding decision trees to an ensemble, with each new tree correcting the errors of the previous trees. GradientBoostingClassifier optimizes the loss function of the model using gradient descent to find the optimal parameters of each tree. It is a powerful algorithm that can handle complex interactions between features and is known for its high accuracy in many classification tasks. However, it can be sensitive to the choice of hyperparameters and may require careful tuning to achieve good performance. GradientBoostingClassifier is widely used in various fields such as finance, healthcare, and marketing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "bdc2b766",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingClassifier()"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "classifier = GradientBoostingClassifier()\n",
    "classifier.fit(X_train_bow, y_train_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ad3c4a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = classifier.predict(X_test_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b9fc7abe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7928809115659978\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.73      0.78      4939\n",
      "           1       0.76      0.85      0.81      4978\n",
      "\n",
      "    accuracy                           0.79      9917\n",
      "   macro avg       0.80      0.79      0.79      9917\n",
      "weighted avg       0.80      0.79      0.79      9917\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "print(accuracy_score(y_test_bow, y_test_pred))\n",
    "\n",
    "print(classification_report(y_test_bow, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807b9065",
   "metadata": {},
   "source": [
    "## AdaBoostClassifier\n",
    "\n",
    "\n",
    "AdaBoostClassifier is a machine learning algorithm used for classification tasks. It is a type of boosting algorithm that works by iteratively adding weak classifiers to an ensemble, with each new classifier focused on classifying the misclassified samples of the previous classifiers. AdaBoostClassifier assigns a weight to each training sample, which is updated after each iteration based on the accuracy of the previous classifiers. The final prediction is determined by a weighted majority vote of the individual classifier predictions. AdaBoostClassifier is a powerful algorithm that can improve the performance of weak classifiers and is known for its ability to handle complex classification problems. However, it can be sensitive to noisy data and outliers and may require careful tuning of hyperparameters to achieve good performance. AdaBoostClassifier is widely used in various fields such as finance, healthcare, and marketing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a800538f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>AdaBoostClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">AdaBoostClassifier</label><div class=\"sk-toggleable__content\"><pre>AdaBoostClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "AdaBoostClassifier()"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "classifier = AdaBoostClassifier()\n",
    "classifier.fit(X_train_bow, y_train_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "dc23ead0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = classifier.predict(X_test_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "18ba28d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7868306947665624\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.74      0.78      4939\n",
      "           1       0.76      0.83      0.80      4978\n",
      "\n",
      "    accuracy                           0.79      9917\n",
      "   macro avg       0.79      0.79      0.79      9917\n",
      "weighted avg       0.79      0.79      0.79      9917\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "print(accuracy_score(y_test_bow, y_test_pred))\n",
    "\n",
    "print(classification_report(y_test_bow, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e821087",
   "metadata": {},
   "source": [
    "## XGBClassifier\n",
    "\n",
    "\n",
    "XGBClassifier (Extreme Gradient Boosting Classifier) is a machine learning algorithm used for classification tasks. It is a type of boosting algorithm that works by iteratively adding decision trees to an ensemble, with each new tree focused on reducing the errors of the previous trees. XGBClassifier optimizes the loss function of the model using gradient descent to find the optimal parameters of each tree. It also uses regularization techniques to prevent overfitting and improve generalization performance. XGBClassifier is known for its high accuracy and speed in many classification tasks, especially in large-scale and high-dimensional datasets. It can handle missing data and outliers and can automatically handle feature selection and feature engineering. However, it may require careful tuning of hyperparameters and can be computationally expensive for very large datasets. XGBClassifier is widely used in various fields such as finance, healthcare, and marketing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e59c7902",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-9 {color: black;background-color: white;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy=&#x27;depthwise&#x27;,\n",
       "              importance_type=None, interaction_constraints=&#x27;&#x27;,\n",
       "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=100,\n",
       "              n_jobs=0, num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" checked><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy=&#x27;depthwise&#x27;,\n",
       "              importance_type=None, interaction_constraints=&#x27;&#x27;,\n",
       "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=100,\n",
       "              n_jobs=0, num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
       "              importance_type=None, interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints='()', n_estimators=100,\n",
       "              n_jobs=0, num_parallel_tree=1, predictor='auto', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, ...)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "classifier = xgb.XGBClassifier()\n",
    "classifier.fit(X_train_bow, y_train_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "6df35eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = classifier.predict(X_test_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d71637a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8462236563476858\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.82      0.84      4939\n",
      "           1       0.83      0.87      0.85      4978\n",
      "\n",
      "    accuracy                           0.85      9917\n",
      "   macro avg       0.85      0.85      0.85      9917\n",
      "weighted avg       0.85      0.85      0.85      9917\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "print(accuracy_score(y_test_bow, y_test_pred))\n",
    "\n",
    "print(classification_report(y_test_bow, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c79705",
   "metadata": {},
   "source": [
    "## In Bag of Words BernoulliNB (Naive Bayes) is giving good accuracy with Instant time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4a8e07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e2a286",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "76aa9b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['GRAMS'] = df.review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "bcd9b79f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>BOW</th>\n",
       "      <th>GRAMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one reviewer mentioned watching oz episode you...</td>\n",
       "      <td>1</td>\n",
       "      <td>one reviewer mentioned watching oz episode you...</td>\n",
       "      <td>one reviewer mentioned watching oz episode you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wonderful little production filming technique ...</td>\n",
       "      <td>1</td>\n",
       "      <td>wonderful little production filming technique ...</td>\n",
       "      <td>wonderful little production filming technique ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thought wonderful way spend time hot summer we...</td>\n",
       "      <td>1</td>\n",
       "      <td>thought wonderful way spend time hot summer we...</td>\n",
       "      <td>thought wonderful way spend time hot summer we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically there family little boy jake think t...</td>\n",
       "      <td>0</td>\n",
       "      <td>basically there family little boy jake think t...</td>\n",
       "      <td>basically there family little boy jake think t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter matteis love time money visually stunni...</td>\n",
       "      <td>1</td>\n",
       "      <td>petter matteis love time money visually stunni...</td>\n",
       "      <td>petter matteis love time money visually stunni...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment  \\\n",
       "0  one reviewer mentioned watching oz episode you...          1   \n",
       "1  wonderful little production filming technique ...          1   \n",
       "2  thought wonderful way spend time hot summer we...          1   \n",
       "3  basically there family little boy jake think t...          0   \n",
       "4  petter matteis love time money visually stunni...          1   \n",
       "\n",
       "                                                 BOW  \\\n",
       "0  one reviewer mentioned watching oz episode you...   \n",
       "1  wonderful little production filming technique ...   \n",
       "2  thought wonderful way spend time hot summer we...   \n",
       "3  basically there family little boy jake think t...   \n",
       "4  petter matteis love time money visually stunni...   \n",
       "\n",
       "                                               GRAMS  \n",
       "0  one reviewer mentioned watching oz episode you...  \n",
       "1  wonderful little production filming technique ...  \n",
       "2  thought wonderful way spend time hot summer we...  \n",
       "3  basically there family little boy jake think t...  \n",
       "4  petter matteis love time money visually stunni...  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88e747e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e55c2c63",
   "metadata": {},
   "source": [
    "# Term Frequency Inverse Document Frequency\n",
    "\n",
    "In BOW approach all the words in the text are treated as equally important i.e. there's no notion of some words in the document being more important than others. TF-IDF, or term frequency-inverse document frequency, addresses this issue. It aims to quantify the importance of a given word relative to other words in the document and in the corpus.\n",
    "\n",
    "***\n",
    "\n",
    "Let's now try to understand:\n",
    "1. Term Frequency  \n",
    "2. Inverse Document Frequency\n",
    "\n",
    "$$ TF \\ IDF = TF(word_i, doc_j) * IDF(word_i, corpus) $$\n",
    "\n",
    "$$ TF(word_i, doc_j) = \\frac{No \\ of \\ time \\ word_i \\ occurs \\ in \\ doc_j}{Total \\ no \\ of \\ words \\ in \\ doc_j} $$\n",
    "\n",
    "$$ IDF(word_i, corpus) = \\log_n(\\frac{No \\ of \\ docs \\ in \\ corpus}{No \\ of \\ docs \\ which \\ contains \\ word_i}) $$\n",
    "\n",
    "***\n",
    "\n",
    "### Advantages\n",
    "1. If the word is rare in the corpus, it will be given more importance. (i.e. IDF)\n",
    "2. If the word is more frequent in a document, it will be given more importance. (i.e. TF)\n",
    "\n",
    "### Disadvantages\n",
    "> **Same as BOW**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "b96ad907",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "2bd938cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.GRAMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "8682c493",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        one reviewer mentioned watching oz episode you...\n",
       "1        wonderful little production filming technique ...\n",
       "2        thought wonderful way spend time hot summer we...\n",
       "3        basically there family little boy jake think t...\n",
       "4        petter matteis love time money visually stunni...\n",
       "                               ...                        \n",
       "49995    thought movie right good job wasnt creative or...\n",
       "49996    bad plot bad dialogue bad acting idiotic direc...\n",
       "49997    catholic taught parochial elementary school nu...\n",
       "49998    im going disagree previous comment side maltin...\n",
       "49999    one expects star trek movie high art fan expec...\n",
       "Name: GRAMS, Length: 49582, dtype: object"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "7170c4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "8e333c57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1\n",
       "1        1\n",
       "2        1\n",
       "3        0\n",
       "4        1\n",
       "        ..\n",
       "49995    1\n",
       "49996    0\n",
       "49997    0\n",
       "49998    0\n",
       "49999    0\n",
       "Name: sentiment, Length: 49582, dtype: int64"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee83d897",
   "metadata": {},
   "source": [
    "**Train Test Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "c47d351a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_ngrams, X_test_ngrams, y_train_ngrams, y_test_ngrams = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "b040f54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range=(1,3))\n",
    "X_train_ngrams = vectorizer.fit_transform(X_train_ngrams)\n",
    "X_test_ngrams = vectorizer.transform(X_test_ngrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5754214",
   "metadata": {},
   "source": [
    "**Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "008cdbff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy: 0.894\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Train the model on the n-grams\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train_ngrams, y_train_ngrams)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_test_pred = clf.predict(X_test_ngrams)\n",
    "accuracy = clf.score(X_test_ngrams, y_test_ngrams)\n",
    "print(f\"Test set accuracy: {accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "d70d23a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8935161843299385\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.88      0.89      4939\n",
      "           1       0.88      0.91      0.90      4978\n",
      "\n",
      "    accuracy                           0.89      9917\n",
      "   macro avg       0.89      0.89      0.89      9917\n",
      "weighted avg       0.89      0.89      0.89      9917\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "print(accuracy_score(y_test_ngrams, y_test_pred))\n",
    "\n",
    "print(classification_report(y_test_ngrams, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49815d68",
   "metadata": {},
   "source": [
    "**MultinomialNB**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "a8213ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy: 0.885\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.88      4939\n",
      "           1       0.89      0.88      0.89      4978\n",
      "\n",
      "    accuracy                           0.89      9917\n",
      "   macro avg       0.89      0.89      0.89      9917\n",
      "weighted avg       0.89      0.89      0.89      9917\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Train the model on the n-grams\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_ngrams, y_train_ngrams)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_test_pred = clf.predict(X_test_ngrams)\n",
    "accuracy = clf.score(X_test_ngrams, y_test_ngrams)\n",
    "print(f\"Test set accuracy: {accuracy:.3f}\")\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "print(classification_report(y_test_ngrams, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a98199d",
   "metadata": {},
   "source": [
    "**Support Vector Machine**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "27bb9e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy: 0.880\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.87      0.88      4939\n",
      "           1       0.88      0.89      0.88      4978\n",
      "\n",
      "    accuracy                           0.88      9917\n",
      "   macro avg       0.88      0.88      0.88      9917\n",
      "weighted avg       0.88      0.88      0.88      9917\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Train the model on the n-grams\n",
    "clf = SVC()\n",
    "clf.fit(X_train_ngrams, y_train_ngrams)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_test_pred = clf.predict(X_test_ngrams)\n",
    "accuracy = clf.score(X_test_ngrams, y_test_ngrams)\n",
    "print(f\"Test set accuracy: {accuracy:.3f}\")\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "print(classification_report(y_test_ngrams, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe6e186",
   "metadata": {},
   "source": [
    "**Random Forest Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "71e435ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy: 0.851\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.83      0.85      4939\n",
      "           1       0.84      0.87      0.85      4978\n",
      "\n",
      "    accuracy                           0.85      9917\n",
      "   macro avg       0.85      0.85      0.85      9917\n",
      "weighted avg       0.85      0.85      0.85      9917\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Train the model on the n-grams\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train_ngrams, y_train_ngrams)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_test_pred = clf.predict(X_test_ngrams)\n",
    "accuracy = clf.score(X_test_ngrams, y_test_ngrams)\n",
    "print(f\"Test set accuracy: {accuracy:.3f}\")\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "print(classification_report(y_test_ngrams, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6000348c",
   "metadata": {},
   "source": [
    "**Decision Tree Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "642fb8a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy: 0.722\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.72      0.72      4939\n",
      "           1       0.72      0.73      0.72      4978\n",
      "\n",
      "    accuracy                           0.72      9917\n",
      "   macro avg       0.72      0.72      0.72      9917\n",
      "weighted avg       0.72      0.72      0.72      9917\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Train the model on the n-grams\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train_ngrams, y_train_ngrams)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_test_pred = clf.predict(X_test_ngrams)\n",
    "accuracy = clf.score(X_test_ngrams, y_test_ngrams)\n",
    "print(f\"Test set accuracy: {accuracy:.3f}\")\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "print(classification_report(y_test_ngrams, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f05253",
   "metadata": {},
   "source": [
    "**KNeighbors Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "765d5e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy: 0.723\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.72      0.72      4939\n",
      "           1       0.72      0.73      0.72      4978\n",
      "\n",
      "    accuracy                           0.72      9917\n",
      "   macro avg       0.72      0.72      0.72      9917\n",
      "weighted avg       0.72      0.72      0.72      9917\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Train the model on the n-grams\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train_ngrams, y_train_ngrams)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_test_pred = clf.predict(X_test_ngrams)\n",
    "accuracy = clf.score(X_test_ngrams, y_test_ngrams)\n",
    "print(f\"Test set accuracy: {accuracy:.3f}\")\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "print(classification_report(y_test_ngrams, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71ac40e",
   "metadata": {},
   "source": [
    "**Gradient Boosting Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "118b4ed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy: 0.799\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.74      0.79      4939\n",
      "           1       0.77      0.86      0.81      4978\n",
      "\n",
      "    accuracy                           0.80      9917\n",
      "   macro avg       0.80      0.80      0.80      9917\n",
      "weighted avg       0.80      0.80      0.80      9917\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Train the model on the n-grams\n",
    "clf = GradientBoostingClassifier()\n",
    "clf.fit(X_train_ngrams, y_train_ngrams)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_test_pred = clf.predict(X_test_ngrams)\n",
    "accuracy = clf.score(X_test_ngrams, y_test_ngrams)\n",
    "print(f\"Test set accuracy: {accuracy:.3f}\")\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "print(classification_report(y_test_ngrams, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653720a4",
   "metadata": {},
   "source": [
    "**AdaBoost Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "160d7d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy: 0.787\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.74      0.78      4939\n",
      "           1       0.76      0.83      0.80      4978\n",
      "\n",
      "    accuracy                           0.79      9917\n",
      "   macro avg       0.79      0.79      0.79      9917\n",
      "weighted avg       0.79      0.79      0.79      9917\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# Train the model on the n-grams\n",
    "clf = AdaBoostClassifier()\n",
    "clf.fit(X_train_ngrams, y_train_ngrams)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_test_pred = clf.predict(X_test_ngrams)\n",
    "accuracy = clf.score(X_test_ngrams, y_test_ngrams)\n",
    "print(f\"Test set accuracy: {accuracy:.3f}\")\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "print(classification_report(y_test_ngrams, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee7254d",
   "metadata": {},
   "source": [
    "**XGBoost Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "fb30565c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy: 0.850\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.82      0.85      4939\n",
      "           1       0.83      0.88      0.85      4978\n",
      "\n",
      "    accuracy                           0.85      9917\n",
      "   macro avg       0.85      0.85      0.85      9917\n",
      "weighted avg       0.85      0.85      0.85      9917\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# Train the model on the n-grams\n",
    "clf = xgb.XGBClassifier()\n",
    "clf.fit(X_train_ngrams, y_train_ngrams)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_test_pred = clf.predict(X_test_ngrams)\n",
    "accuracy = clf.score(X_test_ngrams, y_test_ngrams)\n",
    "print(f\"Test set accuracy: {accuracy:.3f}\")\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "print(classification_report(y_test_ngrams, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59313afd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c76d9046",
   "metadata": {},
   "source": [
    "## Latent Space\n",
    "A latent space, also known as a latent feature space or embedding space, is an embedding of a set of items within a manifold in which items which resemble each other more closely are positioned closer to one another in the latent space.\n",
    "\n",
    "\n",
    "## Word Embeddings (Word Vectors)\n",
    "\n",
    "In natural language processing (NLP), [word embedding](https://en.wikipedia.org/wiki/Word_embedding) is a term used for the representation of words for text analysis, typically in the form of a real-valued vector that encodes the meaning of the word such that the words that are closer in the vector space are expected to be similar in meaning. Word embeddings can be obtained using a set of [language modeling](https://en.wikipedia.org/wiki/Language_model) and [feature learning](https://en.wikipedia.org/wiki/Feature_learning) techniques where words or phrases from the vocabulary are mapped to vectors of real numbers.\n",
    "\n",
    "Methods to generate this mapping include **neural networks**, **dimensionality reduction on the word co-occurrence matrix**, **probabilistic models**, **explainable knowledge base method**, and **explicit representation in terms of the context in which words appear**.\n",
    "\n",
    "Traditionally, one of the main **limitations of word embeddings** (word vector space models in general) is that words with multiple meanings are conflated into a single representation (a single vector in the semantic space). In other words, [polysemy](https://en.wikipedia.org/wiki/Polysemy) and [homonymy](https://en.wikipedia.org/wiki/Homonym) are not handled properly. \n",
    "\n",
    "\n",
    "\n",
    "## Word2Vec\n",
    "\n",
    "\"You shall know the word by the company it keeps.\" by JR Firth\n",
    "\n",
    "**Distributional Semantics (i.e. a word is characterized by the company it keeps)**  \n",
    "W2v works well because there is an idea of meaning distribution in the context.\n",
    "\n",
    "**Algorithms to generate Word2Vec Embeddings**\n",
    "1. SkipGram\n",
    "2. Continuous Bag of Words\n",
    "\n",
    "**Issue**  \n",
    "Even if the word is having three different meaning, W2v will return the weighted average of all three as the output. Now the question is, \n",
    "- Is it possible to segregate the three vectors to represent the words based in the context? \n",
    "$$ OR $$\n",
    "- Is it possible to disambiguate the word vectors based on the context?\n",
    "\n",
    "Word2Vec is not capturing the contextual information. This is where BERT comes handy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619a96de",
   "metadata": {},
   "source": [
    "**`! pip install gensim`**  \n",
    "**`! pip install --upgrade gensim`**  \n",
    "Run this in command promp (admin mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "5e1ef372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting gensim\n",
      "  Downloading gensim-4.3.1-cp310-cp310-win_amd64.whl (24.0 MB)\n",
      "     -------------------------------------- 24.0/24.0 MB 552.4 kB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gensim) (1.23.5)\n",
      "Requirement already satisfied: scipy>=1.7.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gensim) (1.8.1)\n",
      "Collecting smart-open>=1.8.1 (from gensim)\n",
      "  Using cached smart_open-6.3.0-py3-none-any.whl (56 kB)\n",
      "Installing collected packages: smart-open, gensim\n",
      "Successfully installed gensim-4.3.1 smart-open-6.3.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -treamlit (c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -treamlit (c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "bca16f3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gensim version :  4.3.1\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "\n",
    "print(\"gensim version : \", gensim.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "cf76e796",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "6f1acb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokenised_sentences'] = df.review.apply(lambda x : x.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "8d944de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "\n",
    "model = Word2Vec(list(df.tokenised_sentences), vector_size=100, min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "459dcc0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec<vocab=203536, vector_size=100, alpha=0.025>\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "3fc7d6aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49582"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total Documents\n",
    "\n",
    "model.corpus_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "3a88acb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3.96924391e-02  7.05215216e-01  2.77205557e-01 -2.34599322e-01\n",
      " -7.16241956e-01 -7.08722353e-01  4.05035019e-02  3.85503829e-01\n",
      " -3.30744445e-01 -1.96149945e-01 -2.73859113e-01 -1.09544203e-01\n",
      "  3.08331192e-01 -2.98814941e-02  1.15134448e-01 -4.18047994e-01\n",
      "  2.03509688e-01 -1.08542931e+00 -1.88121393e-01 -4.40374225e-01\n",
      " -3.85105573e-02  4.39214826e-01  3.49209219e-01 -6.24152012e-02\n",
      " -6.35484576e-01  2.83000201e-01  8.00740197e-02 -2.28867233e-01\n",
      " -3.62355888e-01  3.81092191e-01  2.46495470e-01 -1.32610306e-01\n",
      "  1.13941208e-02  1.28248995e-02 -1.75871924e-02  5.96926093e-01\n",
      "  5.43491840e-01 -3.69627178e-02 -2.75687069e-01 -5.85657537e-01\n",
      "  5.55438772e-02 -5.31759977e-01  4.14071232e-01  4.29973984e-03\n",
      "  4.23622541e-02 -2.45736048e-01 -2.58015655e-02  1.66570321e-01\n",
      "  2.96422660e-01 -1.27629275e-02 -2.33429715e-01 -6.50721312e-01\n",
      " -1.17209390e-01  1.84230641e-01 -3.35569143e-01  4.60692197e-01\n",
      "  5.64043820e-01 -1.01878516e-01  1.20092317e-01  7.45829418e-02\n",
      " -1.63600296e-01  3.29163641e-01 -2.53946096e-01 -6.58033788e-02\n",
      " -1.07673220e-01  5.73914647e-01 -5.85540719e-02  1.10161617e-01\n",
      " -4.20979410e-01 -2.73661334e-02  1.55074641e-01  4.51083332e-01\n",
      "  5.75432599e-01  4.00876515e-02 -3.87046457e-04 -1.76952016e-02\n",
      " -4.31805402e-01  4.60328132e-01 -4.50815648e-01 -1.24806367e-01\n",
      " -1.63765445e-01 -4.15361002e-02  2.17552409e-01  1.78113785e-02\n",
      " -5.75823151e-02 -1.12272017e-01  3.68274413e-02  1.25101075e-01\n",
      " -1.41927928e-01  1.61627859e-01  7.61467218e-01 -1.07867450e-01\n",
      " -7.19001293e-01  1.83713198e-01  2.88926601e-01  1.68970093e-01\n",
      " -6.75953738e-03 -5.02060354e-01 -9.37766954e-02  1.31423697e-01]\n",
      "(100,)\n"
     ]
    }
   ],
   "source": [
    "# access the 100 dimensional vector for one of the words\n",
    "\n",
    "print(model.wv.__getitem__('foolish'))\n",
    "\n",
    "print(model.wv.__getitem__('foolish').shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "bd8ae288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.7027150e+00  1.4412649e-01 -1.7784105e-01 ...  3.7937871e-01\n",
      "   3.0373713e-01 -1.5447778e-01]\n",
      " [ 1.2232265e+00 -2.9036596e-01 -4.6717882e-01 ...  4.2950651e-01\n",
      "  -1.0309066e+00 -2.7015728e-01]\n",
      " [ 1.2251298e+00  3.1879809e-01 -2.6055372e-01 ...  1.5645322e+00\n",
      "  -8.1740655e-02 -2.5169060e-01]\n",
      " ...\n",
      " [-1.7284574e-02  1.2137000e-02 -1.4008399e-02 ... -6.9863521e-03\n",
      "  -1.6623538e-03 -4.9371952e-03]\n",
      " [-2.3459749e-02  3.5902880e-02  1.8233554e-02 ... -1.2533188e-02\n",
      "  -1.3051795e-02  1.3708739e-02]\n",
      " [-2.1991821e-02  1.6291166e-02  1.5773825e-02 ... -1.7293729e-02\n",
      "   8.0473069e-04 -9.8335138e-03]]\n"
     ]
    }
   ],
   "source": [
    "# Access the 100D vectors for all 6 words\n",
    "\n",
    "print(model.wv.__getitem__(model.wv.index_to_key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "00d3fcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train word2vec model\n",
    "sentences = [text.split() for text in df['GRAMS'].tolist()]\n",
    "model = Word2Vec(sentences, vector_size=300, window=5, min_count=1, workers=4)\n",
    "\n",
    "\n",
    "# create document vectors\n",
    "def get_doc_vector(tokens):\n",
    "    vectors = []\n",
    "    for token in tokens:\n",
    "        if token in model.wv:\n",
    "            vectors.append(model.wv[token])\n",
    "    if len(vectors) > 0:\n",
    "        return np.mean(vectors, axis=0)\n",
    "    else:\n",
    "        return np.zeros(model.vector_size)\n",
    "\n",
    "df['doc_vector_w2v'] = df['GRAMS'].apply(lambda x: get_doc_vector(x.split()))\n",
    "\n",
    "# convert document vectors to numpy array\n",
    "vectors = np.stack(df['doc_vector_w2v'].values)\n",
    "vectors = vectors.astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "5e3fcd42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>BOW</th>\n",
       "      <th>GRAMS</th>\n",
       "      <th>tokenised_sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one reviewer mentioned watching oz episode you...</td>\n",
       "      <td>1</td>\n",
       "      <td>one reviewer mentioned watching oz episode you...</td>\n",
       "      <td>one reviewer mentioned watching oz episode you...</td>\n",
       "      <td>[one, reviewer, mentioned, watching, oz, episo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wonderful little production filming technique ...</td>\n",
       "      <td>1</td>\n",
       "      <td>wonderful little production filming technique ...</td>\n",
       "      <td>wonderful little production filming technique ...</td>\n",
       "      <td>[wonderful, little, production, filming, techn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thought wonderful way spend time hot summer we...</td>\n",
       "      <td>1</td>\n",
       "      <td>thought wonderful way spend time hot summer we...</td>\n",
       "      <td>thought wonderful way spend time hot summer we...</td>\n",
       "      <td>[thought, wonderful, way, spend, time, hot, su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically there family little boy jake think t...</td>\n",
       "      <td>0</td>\n",
       "      <td>basically there family little boy jake think t...</td>\n",
       "      <td>basically there family little boy jake think t...</td>\n",
       "      <td>[basically, there, family, little, boy, jake, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter matteis love time money visually stunni...</td>\n",
       "      <td>1</td>\n",
       "      <td>petter matteis love time money visually stunni...</td>\n",
       "      <td>petter matteis love time money visually stunni...</td>\n",
       "      <td>[petter, matteis, love, time, money, visually,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment  \\\n",
       "0  one reviewer mentioned watching oz episode you...          1   \n",
       "1  wonderful little production filming technique ...          1   \n",
       "2  thought wonderful way spend time hot summer we...          1   \n",
       "3  basically there family little boy jake think t...          0   \n",
       "4  petter matteis love time money visually stunni...          1   \n",
       "\n",
       "                                                 BOW  \\\n",
       "0  one reviewer mentioned watching oz episode you...   \n",
       "1  wonderful little production filming technique ...   \n",
       "2  thought wonderful way spend time hot summer we...   \n",
       "3  basically there family little boy jake think t...   \n",
       "4  petter matteis love time money visually stunni...   \n",
       "\n",
       "                                               GRAMS  \\\n",
       "0  one reviewer mentioned watching oz episode you...   \n",
       "1  wonderful little production filming technique ...   \n",
       "2  thought wonderful way spend time hot summer we...   \n",
       "3  basically there family little boy jake think t...   \n",
       "4  petter matteis love time money visually stunni...   \n",
       "\n",
       "                                 tokenised_sentences  \n",
       "0  [one, reviewer, mentioned, watching, oz, episo...  \n",
       "1  [wonderful, little, production, filming, techn...  \n",
       "2  [thought, wonderful, way, spend, time, hot, su...  \n",
       "3  [basically, there, family, little, boy, jake, ...  \n",
       "4  [petter, matteis, love, time, money, visually,...  "
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ec5dae",
   "metadata": {},
   "source": [
    "**Train Test Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "24d7ea45",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(vectors, df['sentiment'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70653993",
   "metadata": {},
   "source": [
    "**Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "9dbbd0b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8642734697993345\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.86      0.86      4939\n",
      "           1       0.86      0.87      0.87      4978\n",
      "\n",
      "    accuracy                           0.86      9917\n",
      "   macro avg       0.86      0.86      0.86      9917\n",
      "weighted avg       0.86      0.86      0.86      9917\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=42).fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# evaluate classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:', accuracy)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01184b9",
   "metadata": {},
   "source": [
    "**BernoulliNB (Naive Bayes)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "e8a5d962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7308661893717858\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.77      0.74      4939\n",
      "           1       0.75      0.69      0.72      4978\n",
      "\n",
      "    accuracy                           0.73      9917\n",
      "   macro avg       0.73      0.73      0.73      9917\n",
      "weighted avg       0.73      0.73      0.73      9917\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(vectors, df['sentiment'], test_size=0.2, random_state=42)\n",
    "\n",
    "clf = BernoulliNB().fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# evaluate classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:', accuracy)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264c4352",
   "metadata": {},
   "source": [
    "*****************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80cdce0",
   "metadata": {},
   "source": [
    "## Pretrained GloVe Embeddings\n",
    "\n",
    "Pretrained GloVe (Global Vectors) Embeddings is a method for generating word embeddings, which are dense vector representations of words in a high-dimensional space. GloVe embeddings are pretrained on a large corpus of text, such as Wikipedia or Common Crawl, and capture the semantic and syntactic relationships between words. The word embeddings are generated by factorizing a matrix of word co-occurrence probabilities, which captures the frequency of word co-occurrences in a given corpus. GloVe embeddings can be used to initialize the word embeddings in neural network models for various natural language processing tasks, such as text classification, sentiment analysis, and machine translation. Using pretrained GloVe embeddings can save time and resources in training a neural network model and improve its performance, especially when the training data is limited."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "75bc69d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gensim version :  4.3.1\n",
      "['fasttext-wiki-news-subwords-300', 'conceptnet-numberbatch-17-06-300', 'word2vec-ruscorpora-300', 'word2vec-google-news-300', 'glove-wiki-gigaword-50', 'glove-wiki-gigaword-100', 'glove-wiki-gigaword-200', 'glove-wiki-gigaword-300', 'glove-twitter-25', 'glove-twitter-50', 'glove-twitter-100', 'glove-twitter-200', '__testing_word2vec-matrix-synopsis']\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "import gensim.downloader as api\n",
    "\n",
    "print(\"gensim version : \", gensim.__version__)\n",
    "\n",
    "print(list(gensim.downloader.info()['models'].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "5fcec6a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 199.5/199.5MB downloaded\n"
     ]
    }
   ],
   "source": [
    "# Download the pretrained model\n",
    "\n",
    "wv = api.load('glove-twitter-50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "fbc7f266",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gensim.models.keyedvectors.KeyedVectors"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(wv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "caeef5cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1193514\n",
      "(50,)\n"
     ]
    }
   ],
   "source": [
    "# Vocabulary Size and Word Embedding Shape\n",
    "\n",
    "print(len(wv.index_to_key))\n",
    "\n",
    "print(wv.__getitem__(\"school\").shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "496dfe22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('demoday', 0.7418383359909058),\n",
       " ('greenbuild', 0.7343612313270569),\n",
       " ('arbitrage', 0.7243715524673462),\n",
       " ('linkup', 0.7228308320045471),\n",
       " ('windsurfing', 0.7213045954704285)]"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.most_similar(\"boxoffice\", topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "5ee64162",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-6.2160e-02,  3.4587e-01, -2.9080e-01,  2.0121e-02,  6.3709e-01,\n",
       "        9.6714e-01,  7.6739e-01, -1.5875e-01,  2.1479e-01,  1.2500e-01,\n",
       "        3.9027e-01,  1.3916e-01, -3.2726e+00,  5.2209e-01,  4.2103e-01,\n",
       "        1.3496e-01, -1.9587e-01,  2.4054e-01,  2.2643e-02, -4.3547e-02,\n",
       "       -6.3343e-01, -5.6613e-02,  1.8312e-01,  1.9258e-01,  1.2857e-01,\n",
       "        4.5956e-01, -2.3134e-02,  6.2613e-01, -7.4760e-01,  3.1698e-01,\n",
       "        6.5704e-01, -5.2548e-01, -3.4984e-01, -1.5818e-01,  1.2848e+00,\n",
       "       -1.6561e-02,  3.3569e-01, -4.0193e-01,  5.0649e-01, -1.1078e+00,\n",
       "       -6.0371e-01, -4.6247e-01,  7.3285e-01,  1.0590e-01,  6.3736e-01,\n",
       "        5.3980e-01, -6.6086e-01,  1.9400e-01,  1.0077e-03, -3.3654e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.__getitem__('action')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7974da12",
   "metadata": {},
   "source": [
    "### Semantic regularities captured in word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "105e3b49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5667881"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.similarity(\"marvel\", \"dc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "f6263dbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.73921376"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.similarity(\"marvel\", \"ironman\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "99870da2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.54056686"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.similarity(\"dc\", \"batman\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "48fe592d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2894429"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.similarity(\"marvel\", \"boxoffice\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd710db",
   "metadata": {},
   "source": [
    "### Sentence Embedding from Pretrained Model (Document Vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "ae751f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_vector_pretrained(doc, keyed_vectors):\n",
    "    \"\"\"Remove out-of-vocabulary words. Create document vectors by averaging word vectors.\"\"\"\n",
    "    vocab_tokens = [word for word in doc if word in keyed_vectors.index_to_key]\n",
    "    return np.mean(keyed_vectors.__getitem__(vocab_tokens), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "0fd26ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['doc_vector_pretrained_glove'] = df.tokenised_sentences.apply(lambda x : document_vector_pretrained(x, wv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "546706f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>BOW</th>\n",
       "      <th>GRAMS</th>\n",
       "      <th>tokenised_sentences</th>\n",
       "      <th>doc_vector_pretrained_glove</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one reviewer mentioned watching oz episode you...</td>\n",
       "      <td>1</td>\n",
       "      <td>one reviewer mentioned watching oz episode you...</td>\n",
       "      <td>one reviewer mentioned watching oz episode you...</td>\n",
       "      <td>[one, reviewer, mentioned, watching, oz, episo...</td>\n",
       "      <td>[-0.05763471, 0.15613776, 0.123974755, 0.07097...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wonderful little production filming technique ...</td>\n",
       "      <td>1</td>\n",
       "      <td>wonderful little production filming technique ...</td>\n",
       "      <td>wonderful little production filming technique ...</td>\n",
       "      <td>[wonderful, little, production, filming, techn...</td>\n",
       "      <td>[-0.1464626, 0.055594705, 0.20031905, 0.095112...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thought wonderful way spend time hot summer we...</td>\n",
       "      <td>1</td>\n",
       "      <td>thought wonderful way spend time hot summer we...</td>\n",
       "      <td>thought wonderful way spend time hot summer we...</td>\n",
       "      <td>[thought, wonderful, way, spend, time, hot, su...</td>\n",
       "      <td>[-0.057774436, 0.16328157, 0.16948354, 0.02310...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically there family little boy jake think t...</td>\n",
       "      <td>0</td>\n",
       "      <td>basically there family little boy jake think t...</td>\n",
       "      <td>basically there family little boy jake think t...</td>\n",
       "      <td>[basically, there, family, little, boy, jake, ...</td>\n",
       "      <td>[-0.026222777, 0.32340047, 0.0689116, 0.028357...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter matteis love time money visually stunni...</td>\n",
       "      <td>1</td>\n",
       "      <td>petter matteis love time money visually stunni...</td>\n",
       "      <td>petter matteis love time money visually stunni...</td>\n",
       "      <td>[petter, matteis, love, time, money, visually,...</td>\n",
       "      <td>[-0.0066001164, 0.16657418, 0.009746445, 0.128...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment  \\\n",
       "0  one reviewer mentioned watching oz episode you...          1   \n",
       "1  wonderful little production filming technique ...          1   \n",
       "2  thought wonderful way spend time hot summer we...          1   \n",
       "3  basically there family little boy jake think t...          0   \n",
       "4  petter matteis love time money visually stunni...          1   \n",
       "\n",
       "                                                 BOW  \\\n",
       "0  one reviewer mentioned watching oz episode you...   \n",
       "1  wonderful little production filming technique ...   \n",
       "2  thought wonderful way spend time hot summer we...   \n",
       "3  basically there family little boy jake think t...   \n",
       "4  petter matteis love time money visually stunni...   \n",
       "\n",
       "                                               GRAMS  \\\n",
       "0  one reviewer mentioned watching oz episode you...   \n",
       "1  wonderful little production filming technique ...   \n",
       "2  thought wonderful way spend time hot summer we...   \n",
       "3  basically there family little boy jake think t...   \n",
       "4  petter matteis love time money visually stunni...   \n",
       "\n",
       "                                 tokenised_sentences  \\\n",
       "0  [one, reviewer, mentioned, watching, oz, episo...   \n",
       "1  [wonderful, little, production, filming, techn...   \n",
       "2  [thought, wonderful, way, spend, time, hot, su...   \n",
       "3  [basically, there, family, little, boy, jake, ...   \n",
       "4  [petter, matteis, love, time, money, visually,...   \n",
       "\n",
       "                         doc_vector_pretrained_glove  \n",
       "0  [-0.05763471, 0.15613776, 0.123974755, 0.07097...  \n",
       "1  [-0.1464626, 0.055594705, 0.20031905, 0.095112...  \n",
       "2  [-0.057774436, 0.16328157, 0.16948354, 0.02310...  \n",
       "3  [-0.026222777, 0.32340047, 0.0689116, 0.028357...  \n",
       "4  [-0.0066001164, 0.16657418, 0.009746445, 0.128...  "
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "e0c464b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 49582 entries, 0 to 49999\n",
      "Data columns (total 6 columns):\n",
      " #   Column                       Non-Null Count  Dtype \n",
      "---  ------                       --------------  ----- \n",
      " 0   review                       49582 non-null  object\n",
      " 1   sentiment                    49582 non-null  int64 \n",
      " 2   BOW                          49582 non-null  object\n",
      " 3   GRAMS                        49582 non-null  object\n",
      " 4   tokenised_sentences          49582 non-null  object\n",
      " 5   doc_vector_pretrained_glove  49582 non-null  object\n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 3.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09564b51",
   "metadata": {},
   "source": [
    "**Train Test Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "7cfb39b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['doc_vector_pretrained_glove'], df['sentiment'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b9c183",
   "metadata": {},
   "source": [
    "**Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "664595be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7752344459009781\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.78      0.77      4939\n",
      "           1       0.78      0.77      0.78      4978\n",
      "\n",
      "    accuracy                           0.78      9917\n",
      "   macro avg       0.78      0.78      0.78      9917\n",
      "weighted avg       0.78      0.78      0.78      9917\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression().fit(X_train.tolist(), y_train)\n",
    "y_pred = clf.predict(X_test.tolist())\n",
    "\n",
    "# evaluate classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:', accuracy)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3df54eb",
   "metadata": {},
   "source": [
    "**BernoulliNB (Naive Bayes)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "d487a271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6982958556014924\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.72      0.70      4939\n",
      "           1       0.71      0.68      0.69      4978\n",
      "\n",
      "    accuracy                           0.70      9917\n",
      "   macro avg       0.70      0.70      0.70      9917\n",
      "weighted avg       0.70      0.70      0.70      9917\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['doc_vector_pretrained_glove'], df['sentiment'], test_size=0.2, random_state=42)\n",
    "\n",
    "clf = BernoulliNB().fit(X_train.tolist(), y_train)\n",
    "y_pred = clf.predict(X_test.tolist())\n",
    "\n",
    "# evaluate classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:', accuracy)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c9a868",
   "metadata": {},
   "source": [
    "## Pretrained GloVe wont give the better result in compare to other.\n",
    "\n",
    "## For Good Result I need to try different Pretrained Glove Model but its time consuming that why I move forward to use BERT Model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4186c05",
   "metadata": {},
   "source": [
    "***********"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fddbc13d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8449b90b",
   "metadata": {},
   "source": [
    "## Word2Vec vs BERT\n",
    "\n",
    "**Embeddings**  \n",
    "Word2Vec offers pre-trained word embeddings that anyone can use off-the-shelf. The embeddings are key: value pairs, essentially 1-1 mappings between words and their respective vectors. Word2Vec takes a single word as input and outputs a single vector representation of that word. \n",
    "\n",
    "Since BERT generates contextual embeddings, it takes as input a sequence (usually a sentence) rather than a single word. BERT needs to be shown the context that surrounding words provide before it can generate a word embedding. With BERT, you do need to have the actual model as the vector representations of words will vary based on the specific sequences you’re inputting. The output is a fixed-length vector representation of the input sentence. \n",
    "\n",
    "BERT or Bidirectional Encoder Representations from Transformers, is a technique that allows for bidirectional training of Transformers for natural language modeling tasks. Language models which are bidirectionally trained can learn deeper context from language than single-direction models. BERT generates context aware embeddings that allow for multiple representations (each representation, in this case, is a vector) of each word based on a given word’s context.\n",
    "\n",
    "**Word Ordering**  \n",
    "Word2Vec embeddings do not take into account the word position.\n",
    "\n",
    "BERT model explicitly takes as input the position (index) of each word in the sentence before calculating its embedding.\n",
    "\n",
    "**Out-of-Vocabulary**  \n",
    "Since Word2Vec learns embeddings at word level, it can only generate embeddings for words that existed in it’s training set (aka it’s “vocabulary space”). This is a major drawback to Word2Vec - that it just doesn’t support Out-of-Vocabulary words.\n",
    "\n",
    "Alternatively, BERT learns representations at the subword level, so a BERT model will have a smaller vocabulary space than the number of unique words in its training corpus. In turn, BERT is able to generate embeddings for words outside of its vocabulary space giving it a near infinite vocabulary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "81da5c4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -treamlit (c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -treamlit (c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -treamlit (c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -treamlit (c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -treamlit (c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -treamlit (c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
      "     -------------------------------------- 86.0/86.0 kB 131.0 kB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence-transformers) (4.27.4)\n",
      "Requirement already satisfied: tqdm in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence-transformers) (4.64.1)\n",
      "Collecting torch>=1.6.0 (from sentence-transformers)\n",
      "  Downloading torch-2.0.0-cp310-cp310-win_amd64.whl (172.3 MB)\n",
      "     ------------------------------------ 172.3/172.3 MB 394.6 kB/s eta 0:00:00\n",
      "Collecting torchvision (from sentence-transformers)\n",
      "  Downloading torchvision-0.15.1-cp310-cp310-win_amd64.whl (1.2 MB)\n",
      "     ---------------------------------------- 1.2/1.2 MB 736.7 kB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence-transformers) (1.23.5)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence-transformers) (1.2.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence-transformers) (1.8.1)\n",
      "Requirement already satisfied: nltk in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence-transformers) (3.7)\n",
      "Collecting sentencepiece (from sentence-transformers)\n",
      "  Downloading sentencepiece-0.1.98-cp310-cp310-win_amd64.whl (977 kB)\n",
      "     ------------------------------------ 977.8/977.8 kB 427.0 kB/s eta 0:00:00\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence-transformers) (0.13.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.8.0)\n",
      "Requirement already satisfied: requests in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.28.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.5.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (20.9)\n",
      "Collecting sympy (from torch>=1.6.0->sentence-transformers)\n",
      "  Using cached sympy-1.11.1-py3-none-any.whl (6.5 MB)\n",
      "Requirement already satisfied: networkx in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=1.6.0->sentence-transformers) (2.6.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=1.6.0->sentence-transformers) (3.1.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.5)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2022.10.31)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.13.3)\n",
      "Requirement already satisfied: click in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk->sentence-transformers) (7.1.2)\n",
      "Requirement already satisfied: joblib in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk->sentence-transformers) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.1.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torchvision->sentence-transformers) (9.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence-transformers) (3.0.9)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->torch>=1.6.0->sentence-transformers) (2.1.2)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (1.26.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2022.6.15.2)\n",
      "Collecting mpmath>=0.19 (from sympy->torch>=1.6.0->sentence-transformers)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Building wheels for collected packages: sentence-transformers\n",
      "  Building wheel for sentence-transformers (setup.py): started\n",
      "  Building wheel for sentence-transformers (setup.py): finished with status 'done'\n",
      "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125973 sha256=f0de02500744073b954b4f8e0950c099544d8b52cd93cd662fa3d7cd736b72cc\n",
      "  Stored in directory: c:\\users\\admin\\appdata\\local\\pip\\cache\\wheels\\62\\f2\\10\\1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\n",
      "Successfully built sentence-transformers\n",
      "Installing collected packages: sentencepiece, mpmath, sympy, torch, torchvision, sentence-transformers\n",
      "Successfully installed mpmath-1.3.0 sentence-transformers-2.2.2 sentencepiece-0.1.98 sympy-1.11.1 torch-2.0.0 torchvision-0.15.1\n"
     ]
    }
   ],
   "source": [
    "# Installng sentence transformers\n",
    "\n",
    "! pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f763540",
   "metadata": {},
   "source": [
    "## Sentence BERT (SBERT)\n",
    "\n",
    "**`! pip install -U sentence-transformers`**\n",
    "\n",
    "Sentence BERT References:  \n",
    "https://www.sbert.net/index.html  \n",
    "https://www.sbert.net/docs/pretrained_models.html  \n",
    "\n",
    "Find the paper for Sentence BERT here: https://arxiv.org/pdf/1908.10084.pdf\n",
    "\n",
    "**BERT (Devlin et al., 2018) and RoBERTa (Liu et al., 2019) has set a new state-of-the-art performance on sentence-pair regression tasks like semantic textual similarity (STS). However, it requires that both sentences are fed into the network, which causes a massive computational overhead: Finding the most similar pair in a collection of 10,000 sentences requires about 50 million inference computations (~65 hours) with BERT. The construction of BERT makes it unsuitable for semantic similarity search as well as for unsupervised tasks like clustering.**\n",
    "\n",
    "**Sentence-BERT (SBERT), a modification of the pretrained BERT network that use siamese and triplet network structures to derive semantically meaningful sentence embeddings that can be compared using cosine-similarity. This reduces the effort for finding the most similar pair from 65 hours with BERT / RoBERTa to about 5 seconds with SBERT, while maintaining the accuracy from BERT.**\n",
    "\n",
    "### Usage\n",
    "\n",
    "- Computing Sentence Embeddings\n",
    "- Semantic Textual Similarity\n",
    "- Semantic Search\n",
    "- Retrieve and Re-Rank\n",
    "- Clustering\n",
    "- Paraphrase Mining\n",
    "- Translated Sentence Mining\n",
    "- Cross Encoders\n",
    "- Image Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "01ab7215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Sentence Transformer\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, util"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523adfb7",
   "metadata": {},
   "source": [
    "### Model Overview\n",
    "\n",
    "```\n",
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('model_name')\n",
    "```\n",
    "\n",
    "All models are hosted on the [HuggingFace Model Hub](https://huggingface.co/sentence-transformers).\n",
    "\n",
    "The following table provides an overview of (selected) models. They have been extensively evaluated for their quality to embedded sentences (Performance Sentence Embeddings) and to embedded search queries & paragraphs (Performance Semantic Search).\n",
    "\n",
    "The **all-* models** where trained on all available training data (more than 1 billion training pairs) and are designed as general purpose models. The **all-mpnet-base-v2** model provides the best quality, while **all-MiniLM-L6-v2 is 5 times faster** and still offers good quality. Toggle All models to see all evaluated models or visit [HuggingFace Model Hub](https://huggingface.co/models?library=sentence-transformers) to view all existing sentence-transformers models.\n",
    "\n",
    "#### Model Name  \n",
    "**`all-mpnet-base-v2`**\n",
    "> Description: \tAll-round model tuned for many use-cases. Trained on a large and diverse dataset of over 1 billion training pairs.  \n",
    "> Dimensions: \t768  \n",
    "> Suitable Score Functions: \tdot-product (util.dot_score), cosine-similarity (util.cos_sim), euclidean distance  \n",
    "> Size: \t420 MB  \n",
    "> Training Data: \t1B+ training pairs. For details, see model card.  \n",
    "> Model Card: \thttps://huggingface.co/sentence-transformers/all-mpnet-base-v2\n",
    "\n",
    "**`multi-qa-mpnet-base-dot-v1`**\n",
    "> Description: \tThis model was tuned for semantic search: Given a query/question, if can find relevant passages. It was trained on a large and diverse set of (question, answer) pairs.  \n",
    "> Dimensions: \t768  \n",
    "> Suitable Score Functions: \tdot-product (util.dot_score)  \n",
    "> Size: \t420 MB  \n",
    "> Training Data: \t215M (question, answer) pairs from diverse sources.  \n",
    "> Model Card: \thttps://huggingface.co/sentence-transformers/multi-qa-mpnet-base-dot-v1\n",
    "\n",
    "**`all-distilroberta-v1`**\n",
    "> Description: \tAll-round model tuned for many use-cases. Trained on a large and diverse dataset of over 1 billion training pairs.  \n",
    "> Dimensions:\t768  \n",
    "> Suitable Score Functions:\tdot-product (util.dot_score), cosine-similarity (util.cos_sim), euclidean distance  \n",
    "> Size:\t290 MB  \n",
    "> Training Data:\t1B+ training pairs. For details, see model card.  \n",
    "> Model Card: \thttps://huggingface.co/sentence-transformers/all-distilroberta-v1\n",
    "\n",
    "**`all-MiniLM-L6-v2`**\n",
    "> Description: \tAll-round model tuned for many use-cases. Trained on a large and diverse dataset of over 1 billion training pairs.  \n",
    "> Dimensions: \t384  \n",
    "> Suitable Score Functions: \tdot-product (util.dot_score), cosine-similarity (util.cos_sim), euclidean distance  \n",
    "> Size: \t80 MB  \n",
    "> Training Data: \t1B+ training pairs. For details, see model card.  \n",
    "> Model Card: \thttps://huggingface.co/sentence-transformers/all-MiniLM-L6-v2\n",
    "\n",
    "\n",
    "**List of Pretrained models available:**\n",
    "```\n",
    "all-MiniLM-L12-v2\n",
    "multi-qa-distilbert-cos-v1\n",
    "multi-qa-MiniLM-L6-cos-v1\n",
    "multi-qa-MiniLM-L6-cos-v1\n",
    "paraphrase-multilingual-mpnet-base-v2\n",
    "paraphrase-albert-small-v2\n",
    "paraphrase-multilingual-MiniLM-L12-v2\n",
    "paraphrase-MiniLM-L3-v2\n",
    "distiluse-base-multilingual-cased-v1\n",
    "distiluse-base-multilingual-cased-v2\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "309cfa2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0710ca0d4a4464fa00c1fe93571f4d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)e9125/.gitattributes:   0%|          | 0.00/1.18k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6a7a49f293c4e08a1aa481c260c9e3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f1f338179ed4b1fa1031ab6bc0e5d8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)7e55de9125/README.md:   0%|          | 0.00/10.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c980fd4d195848a8b45c32acdfb1b7dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)55de9125/config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79ea047a35664b9f83311c887d51a4ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)ce_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55a48a34459547b38abb0c02ee6e2d0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)125/data_config.json:   0%|          | 0.00/39.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97c14539ec8742e784a97c53cd50de46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1096a2b79d1a47b6bde41dec7d81a1ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)nce_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0d4fc8a532345b89febf3f5ff58c16b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4b5b4a503574d31a08f79fd6d9b3805",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)e9125/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8da303eea18d479cb42fde1bf6d09740",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f3a83d64bc448ccbeecb663f42da6af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)9125/train_script.py:   0%|          | 0.00/13.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1af01a9d7ac42fa9ce041315e7601a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)7e55de9125/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76d56bc3359447ad905bb427867fac13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)5de9125/modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Downloading pretrained model\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "6d7cbde3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86c29b0df634480c96c9a169e62d2857",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/49582 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Applying pretained bert model to our tokenised data\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "df['doc_vector_pretrained_bert'] = df.tokenised_sentences.progress_apply(model.encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "429c3748",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>BOW</th>\n",
       "      <th>GRAMS</th>\n",
       "      <th>tokenised_sentences</th>\n",
       "      <th>doc_vector_pretrained_glove</th>\n",
       "      <th>doc_vector_pretrained_bert</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one reviewer mentioned watching oz episode you...</td>\n",
       "      <td>1</td>\n",
       "      <td>one reviewer mentioned watching oz episode you...</td>\n",
       "      <td>one reviewer mentioned watching oz episode you...</td>\n",
       "      <td>[one, reviewer, mentioned, watching, oz, episo...</td>\n",
       "      <td>[-0.05763471, 0.15613776, 0.123974755, 0.07097...</td>\n",
       "      <td>[[-0.034243144, -0.01212337, -0.034629308, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wonderful little production filming technique ...</td>\n",
       "      <td>1</td>\n",
       "      <td>wonderful little production filming technique ...</td>\n",
       "      <td>wonderful little production filming technique ...</td>\n",
       "      <td>[wonderful, little, production, filming, techn...</td>\n",
       "      <td>[-0.1464626, 0.055594705, 0.20031905, 0.095112...</td>\n",
       "      <td>[[-0.08132241, -0.017621832, -0.028994542, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thought wonderful way spend time hot summer we...</td>\n",
       "      <td>1</td>\n",
       "      <td>thought wonderful way spend time hot summer we...</td>\n",
       "      <td>thought wonderful way spend time hot summer we...</td>\n",
       "      <td>[thought, wonderful, way, spend, time, hot, su...</td>\n",
       "      <td>[-0.057774436, 0.16328157, 0.16948354, 0.02310...</td>\n",
       "      <td>[[-0.029396975, 0.009394713, -0.045678526, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically there family little boy jake think t...</td>\n",
       "      <td>0</td>\n",
       "      <td>basically there family little boy jake think t...</td>\n",
       "      <td>basically there family little boy jake think t...</td>\n",
       "      <td>[basically, there, family, little, boy, jake, ...</td>\n",
       "      <td>[-0.026222777, 0.32340047, 0.0689116, 0.028357...</td>\n",
       "      <td>[[0.019968431, 0.024494648, -0.013714673, 0.07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter matteis love time money visually stunni...</td>\n",
       "      <td>1</td>\n",
       "      <td>petter matteis love time money visually stunni...</td>\n",
       "      <td>petter matteis love time money visually stunni...</td>\n",
       "      <td>[petter, matteis, love, time, money, visually,...</td>\n",
       "      <td>[-0.0066001164, 0.16657418, 0.009746445, 0.128...</td>\n",
       "      <td>[[0.0073643555, 0.028004704, 0.0043900185, -0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment  \\\n",
       "0  one reviewer mentioned watching oz episode you...          1   \n",
       "1  wonderful little production filming technique ...          1   \n",
       "2  thought wonderful way spend time hot summer we...          1   \n",
       "3  basically there family little boy jake think t...          0   \n",
       "4  petter matteis love time money visually stunni...          1   \n",
       "\n",
       "                                                 BOW  \\\n",
       "0  one reviewer mentioned watching oz episode you...   \n",
       "1  wonderful little production filming technique ...   \n",
       "2  thought wonderful way spend time hot summer we...   \n",
       "3  basically there family little boy jake think t...   \n",
       "4  petter matteis love time money visually stunni...   \n",
       "\n",
       "                                               GRAMS  \\\n",
       "0  one reviewer mentioned watching oz episode you...   \n",
       "1  wonderful little production filming technique ...   \n",
       "2  thought wonderful way spend time hot summer we...   \n",
       "3  basically there family little boy jake think t...   \n",
       "4  petter matteis love time money visually stunni...   \n",
       "\n",
       "                                 tokenised_sentences  \\\n",
       "0  [one, reviewer, mentioned, watching, oz, episo...   \n",
       "1  [wonderful, little, production, filming, techn...   \n",
       "2  [thought, wonderful, way, spend, time, hot, su...   \n",
       "3  [basically, there, family, little, boy, jake, ...   \n",
       "4  [petter, matteis, love, time, money, visually,...   \n",
       "\n",
       "                         doc_vector_pretrained_glove  \\\n",
       "0  [-0.05763471, 0.15613776, 0.123974755, 0.07097...   \n",
       "1  [-0.1464626, 0.055594705, 0.20031905, 0.095112...   \n",
       "2  [-0.057774436, 0.16328157, 0.16948354, 0.02310...   \n",
       "3  [-0.026222777, 0.32340047, 0.0689116, 0.028357...   \n",
       "4  [-0.0066001164, 0.16657418, 0.009746445, 0.128...   \n",
       "\n",
       "                          doc_vector_pretrained_bert  \n",
       "0  [[-0.034243144, -0.01212337, -0.034629308, 0.0...  \n",
       "1  [[-0.08132241, -0.017621832, -0.028994542, -0....  \n",
       "2  [[-0.029396975, 0.009394713, -0.045678526, -0....  \n",
       "3  [[0.019968431, 0.024494648, -0.013714673, 0.07...  \n",
       "4  [[0.0073643555, 0.028004704, 0.0043900185, -0....  "
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b86be25",
   "metadata": {},
   "source": [
    "**Train Test Split***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "1016a052",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['doc_vector_pretrained_bert'], df['sentiment'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e73836e",
   "metadata": {},
   "source": [
    "**Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "e160c1e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7752344459009781\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.78      0.77      4939\n",
      "           1       0.78      0.77      0.78      4978\n",
      "\n",
      "    accuracy                           0.78      9917\n",
      "   macro avg       0.78      0.78      0.78      9917\n",
      "weighted avg       0.78      0.78      0.78      9917\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression().fit(X_train.tolist(), y_train)\n",
    "y_pred = clf.predict(X_test.tolist())\n",
    "\n",
    "# evaluate classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:', accuracy)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26565ced",
   "metadata": {},
   "source": [
    "**BernoulliNB (Naive Bayes)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "8e8bacf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6982958556014924\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.72      0.70      4939\n",
      "           1       0.71      0.68      0.69      4978\n",
      "\n",
      "    accuracy                           0.70      9917\n",
      "   macro avg       0.70      0.70      0.70      9917\n",
      "weighted avg       0.70      0.70      0.70      9917\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['doc_vector_pretrained_glove'], df['sentiment'], test_size=0.2, random_state=42)\n",
    "\n",
    "clf = BernoulliNB().fit(X_train.tolist(), y_train)\n",
    "y_pred = clf.predict(X_test.tolist())\n",
    "\n",
    "# evaluate classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:', accuracy)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d6c955",
   "metadata": {},
   "source": [
    "**Gaussian Naïve Bayes**\n",
    "\n",
    "Gaussian Naïve Bayes is a simple probabilistic algorithm used for classification. It is based on Bayes' theorem and assumes that the features are independent of each other. Gaussian Naïve Bayes assumes that the probability distribution of the features is Gaussian, and it calculates the probability of each class given the features using Bayes' theorem. It is a fast and simple algorithm that works well on small to medium-sized datasets with high-dimensional feature spaces. It is commonly used in natural language processing and text classification tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "d595e451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7104971261470203\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.74      0.72      4939\n",
      "           1       0.72      0.68      0.70      4978\n",
      "\n",
      "    accuracy                           0.71      9917\n",
      "   macro avg       0.71      0.71      0.71      9917\n",
      "weighted avg       0.71      0.71      0.71      9917\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['doc_vector_pretrained_glove'], df['sentiment'], test_size=0.2, random_state=42)\n",
    "\n",
    "clf = GaussianNB().fit(X_train.tolist(), y_train)\n",
    "y_pred = clf.predict(X_test.tolist())\n",
    "\n",
    "# evaluate classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:', accuracy)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "02eda2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving file as csv\n",
    "\n",
    "df.to_csv(\"model.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d584babb",
   "metadata": {},
   "source": [
    "***********"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9387d5a",
   "metadata": {},
   "source": [
    "# Deep Learning\n",
    "\n",
    "\n",
    "Deep learning is a subset of machine learning that is based on artificial neural networks that simulate the way the human brain works. It involves training a model on a large dataset to learn complex representations of data, with the aim of achieving high accuracy on a given task, such as image or speech recognition, natural language processing, and decision making. Deep learning models typically have multiple layers of artificial neurons, which are trained using backpropagation to adjust the weights and biases in order to minimize the error between the predicted output and the actual output. The main advantage of deep learning is its ability to automatically extract features from raw data, making it possible to solve a wide range of complex problems with high accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "5fc47933",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>BOW</th>\n",
       "      <th>GRAMS</th>\n",
       "      <th>tokenised_sentences</th>\n",
       "      <th>doc_vector_pretrained_glove</th>\n",
       "      <th>doc_vector_pretrained_bert</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one reviewer mentioned watching oz episode you...</td>\n",
       "      <td>1</td>\n",
       "      <td>one reviewer mentioned watching oz episode you...</td>\n",
       "      <td>one reviewer mentioned watching oz episode you...</td>\n",
       "      <td>[one, reviewer, mentioned, watching, oz, episo...</td>\n",
       "      <td>[-0.05763471, 0.15613776, 0.123974755, 0.07097...</td>\n",
       "      <td>[[-0.034243144, -0.01212337, -0.034629308, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wonderful little production filming technique ...</td>\n",
       "      <td>1</td>\n",
       "      <td>wonderful little production filming technique ...</td>\n",
       "      <td>wonderful little production filming technique ...</td>\n",
       "      <td>[wonderful, little, production, filming, techn...</td>\n",
       "      <td>[-0.1464626, 0.055594705, 0.20031905, 0.095112...</td>\n",
       "      <td>[[-0.08132241, -0.017621832, -0.028994542, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thought wonderful way spend time hot summer we...</td>\n",
       "      <td>1</td>\n",
       "      <td>thought wonderful way spend time hot summer we...</td>\n",
       "      <td>thought wonderful way spend time hot summer we...</td>\n",
       "      <td>[thought, wonderful, way, spend, time, hot, su...</td>\n",
       "      <td>[-0.057774436, 0.16328157, 0.16948354, 0.02310...</td>\n",
       "      <td>[[-0.029396975, 0.009394713, -0.045678526, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically there family little boy jake think t...</td>\n",
       "      <td>0</td>\n",
       "      <td>basically there family little boy jake think t...</td>\n",
       "      <td>basically there family little boy jake think t...</td>\n",
       "      <td>[basically, there, family, little, boy, jake, ...</td>\n",
       "      <td>[-0.026222777, 0.32340047, 0.0689116, 0.028357...</td>\n",
       "      <td>[[0.019968431, 0.024494648, -0.013714673, 0.07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter matteis love time money visually stunni...</td>\n",
       "      <td>1</td>\n",
       "      <td>petter matteis love time money visually stunni...</td>\n",
       "      <td>petter matteis love time money visually stunni...</td>\n",
       "      <td>[petter, matteis, love, time, money, visually,...</td>\n",
       "      <td>[-0.0066001164, 0.16657418, 0.009746445, 0.128...</td>\n",
       "      <td>[[0.0073643555, 0.028004704, 0.0043900185, -0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment  \\\n",
       "0  one reviewer mentioned watching oz episode you...          1   \n",
       "1  wonderful little production filming technique ...          1   \n",
       "2  thought wonderful way spend time hot summer we...          1   \n",
       "3  basically there family little boy jake think t...          0   \n",
       "4  petter matteis love time money visually stunni...          1   \n",
       "\n",
       "                                                 BOW  \\\n",
       "0  one reviewer mentioned watching oz episode you...   \n",
       "1  wonderful little production filming technique ...   \n",
       "2  thought wonderful way spend time hot summer we...   \n",
       "3  basically there family little boy jake think t...   \n",
       "4  petter matteis love time money visually stunni...   \n",
       "\n",
       "                                               GRAMS  \\\n",
       "0  one reviewer mentioned watching oz episode you...   \n",
       "1  wonderful little production filming technique ...   \n",
       "2  thought wonderful way spend time hot summer we...   \n",
       "3  basically there family little boy jake think t...   \n",
       "4  petter matteis love time money visually stunni...   \n",
       "\n",
       "                                 tokenised_sentences  \\\n",
       "0  [one, reviewer, mentioned, watching, oz, episo...   \n",
       "1  [wonderful, little, production, filming, techn...   \n",
       "2  [thought, wonderful, way, spend, time, hot, su...   \n",
       "3  [basically, there, family, little, boy, jake, ...   \n",
       "4  [petter, matteis, love, time, money, visually,...   \n",
       "\n",
       "                         doc_vector_pretrained_glove  \\\n",
       "0  [-0.05763471, 0.15613776, 0.123974755, 0.07097...   \n",
       "1  [-0.1464626, 0.055594705, 0.20031905, 0.095112...   \n",
       "2  [-0.057774436, 0.16328157, 0.16948354, 0.02310...   \n",
       "3  [-0.026222777, 0.32340047, 0.0689116, 0.028357...   \n",
       "4  [-0.0066001164, 0.16657418, 0.009746445, 0.128...   \n",
       "\n",
       "                          doc_vector_pretrained_bert  \n",
       "0  [[-0.034243144, -0.01212337, -0.034629308, 0.0...  \n",
       "1  [[-0.08132241, -0.017621832, -0.028994542, -0....  \n",
       "2  [[-0.029396975, 0.009394713, -0.045678526, -0....  \n",
       "3  [[0.019968431, 0.024494648, -0.013714673, 0.07...  \n",
       "4  [[0.0073643555, 0.028004704, 0.0043900185, -0....  "
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35fdc9f1",
   "metadata": {},
   "source": [
    "## An Artificial Neural Network (ANN)\n",
    "\n",
    "An Artificial Neural Network (ANN) classifier is a type of machine learning model that learns to map input data to output classes by training on a set of labeled examples. It consists of multiple layers of interconnected nodes (neurons), each performing a linear or nonlinear operation on its input and passing the result to the next layer. The first layer receives the input data, and the final layer produces the output class predictions. During training, the model adjusts the weights of the connections between the neurons to minimize the difference between its predictions and the true labels of the training examples. ANN classifiers are widely used for tasks such as image classification, natural language processing, and speech recognition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "fbb46110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1240/1240 [==============================] - 56s 31ms/step - loss: 0.4293 - accuracy: 0.8216 - val_loss: 0.2874 - val_accuracy: 0.8841\n",
      "Epoch 2/10\n",
      "1240/1240 [==============================] - 15s 12ms/step - loss: 0.2423 - accuracy: 0.9043 - val_loss: 0.2740 - val_accuracy: 0.8894\n",
      "Epoch 3/10\n",
      "1240/1240 [==============================] - 12s 10ms/step - loss: 0.2058 - accuracy: 0.9214 - val_loss: 0.2791 - val_accuracy: 0.8896\n",
      "Epoch 4/10\n",
      "1240/1240 [==============================] - 12s 10ms/step - loss: 0.1840 - accuracy: 0.9307 - val_loss: 0.2901 - val_accuracy: 0.8869\n",
      "Epoch 5/10\n",
      "1240/1240 [==============================] - 12s 10ms/step - loss: 0.1676 - accuracy: 0.9379 - val_loss: 0.3041 - val_accuracy: 0.8864\n",
      "Epoch 6/10\n",
      "1240/1240 [==============================] - 12s 10ms/step - loss: 0.1544 - accuracy: 0.9437 - val_loss: 0.3230 - val_accuracy: 0.8815\n",
      "Epoch 7/10\n",
      "1240/1240 [==============================] - 13s 10ms/step - loss: 0.1440 - accuracy: 0.9482 - val_loss: 0.3383 - val_accuracy: 0.8802\n",
      "Epoch 8/10\n",
      "1240/1240 [==============================] - 14s 11ms/step - loss: 0.1357 - accuracy: 0.9514 - val_loss: 0.3587 - val_accuracy: 0.8785\n",
      "Epoch 9/10\n",
      "1240/1240 [==============================] - 12s 9ms/step - loss: 0.1275 - accuracy: 0.9556 - val_loss: 0.3774 - val_accuracy: 0.8747\n",
      "Epoch 10/10\n",
      "1240/1240 [==============================] - 11s 9ms/step - loss: 0.1213 - accuracy: 0.9576 - val_loss: 0.3926 - val_accuracy: 0.8736\n",
      "1/1 [==============================] - 0s 487ms/step\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Embedding, Dense, GlobalAveragePooling1D\n",
    "\n",
    "# Convert the tokenized text data to sequences of integers\n",
    "\n",
    "tokenizer = keras.preprocessing.text.Tokenizer(num_words=10000)\n",
    "tokenizer.fit_on_texts(df['GRAMS'])\n",
    "sequences = tokenizer.texts_to_sequences(df['GRAMS'])\n",
    "\n",
    "# Pad sequences to have same length\n",
    "\n",
    "padded_sequences = keras.preprocessing.sequence.pad_sequences(sequences, maxlen=200)\n",
    "\n",
    "# Convert target labels to binary format\n",
    "\n",
    "targets = np.array(df['sentiment'])\n",
    "targets = np.where(targets==1, 1, 0)\n",
    "\n",
    "# Define the model architecture\n",
    "\n",
    "model = keras.Sequential([\n",
    "    Embedding(10000, 16, input_length=200),\n",
    "    GlobalAveragePooling1D(),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "\n",
    "model.fit(padded_sequences, targets, epochs=10, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model on test data\n",
    "\n",
    "test_sequences = tokenizer.texts_to_sequences(['your test data goes here'])\n",
    "padded_test_sequences = keras.preprocessing.sequence.pad_sequences(test_sequences, maxlen=200)\n",
    "predictions = model.predict(padded_test_sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3872f72a",
   "metadata": {},
   "source": [
    "## Recurrent Neural Networks (RNNs)\n",
    "\n",
    "Recurrent Neural Networks (RNNs) are a type of neural network designed for processing sequential data. They are characterized by having a hidden state that is updated at each time step based on the current input and the previous hidden state. RNNs are capable of processing input sequences of variable length, making them useful for tasks such as language modeling, machine translation, and speech recognition. However, they suffer from the vanishing gradient problem, which can make it difficult to train them on long sequences. To overcome this problem, variants of RNNs such as Long Short-Term Memory (LSTM) and Gated Recurrent Unit (GRU) have been developed, which incorporate additional mechanisms to control the flow of information through the network.\n",
    "\n",
    "\n",
    "## LSTM (Long Short-Term Memory)\n",
    "\n",
    "LSTM (Long Short-Term Memory) is a type of recurrent neural network (RNN) that is designed to avoid the vanishing gradient problem. LSTMs are used for modeling sequential data such as time series, speech, and text. LSTMs have a unique memory cell that can maintain information over long periods of time, and they use gates to control the flow of information into and out of the cell. These gates allow the LSTM to selectively forget or remember information from previous time steps, and they also allow the LSTM to add new information to the memory cell. LSTMs have shown to be effective for a wide range of tasks, including language modeling, machine translation, speech recognition, and image captioning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "2e4d4715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1240/1240 [==============================] - 119s 84ms/step - loss: 0.3452 - accuracy: 0.8516 - val_loss: 0.2957 - val_accuracy: 0.8813\n",
      "Epoch 2/10\n",
      "1240/1240 [==============================] - 105s 84ms/step - loss: 0.2235 - accuracy: 0.9136 - val_loss: 0.2977 - val_accuracy: 0.8870\n",
      "Epoch 3/10\n",
      "1240/1240 [==============================] - 104s 84ms/step - loss: 0.1813 - accuracy: 0.9321 - val_loss: 0.3283 - val_accuracy: 0.8747\n",
      "Epoch 4/10\n",
      "1240/1240 [==============================] - 103s 83ms/step - loss: 0.1558 - accuracy: 0.9429 - val_loss: 0.3463 - val_accuracy: 0.8778\n",
      "Epoch 5/10\n",
      "1240/1240 [==============================] - 101s 81ms/step - loss: 0.1351 - accuracy: 0.9506 - val_loss: 0.3859 - val_accuracy: 0.8699\n",
      "Epoch 6/10\n",
      "1240/1240 [==============================] - 108s 87ms/step - loss: 0.1167 - accuracy: 0.9580 - val_loss: 0.3873 - val_accuracy: 0.8695\n",
      "Epoch 7/10\n",
      "1240/1240 [==============================] - 101s 82ms/step - loss: 0.1007 - accuracy: 0.9654 - val_loss: 0.4488 - val_accuracy: 0.8676\n",
      "Epoch 8/10\n",
      "1240/1240 [==============================] - 101s 81ms/step - loss: 0.0866 - accuracy: 0.9699 - val_loss: 0.4442 - val_accuracy: 0.8674\n",
      "Epoch 9/10\n",
      "1240/1240 [==============================] - 102s 82ms/step - loss: 0.0741 - accuracy: 0.9751 - val_loss: 0.4807 - val_accuracy: 0.8608\n",
      "Epoch 10/10\n",
      "1240/1240 [==============================] - 102s 82ms/step - loss: 0.0736 - accuracy: 0.9755 - val_loss: 0.4967 - val_accuracy: 0.8598\n",
      "1/1 [==============================] - 1s 659ms/step\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "\n",
    "# Convert the tokenized text data to sequences of integers\n",
    "\n",
    "tokenizer = keras.preprocessing.text.Tokenizer(num_words=10000)\n",
    "tokenizer.fit_on_texts(df['GRAMS'])\n",
    "sequences = tokenizer.texts_to_sequences(df['GRAMS'])\n",
    "\n",
    "# Pad sequences to have same length\n",
    "\n",
    "padded_sequences = keras.preprocessing.sequence.pad_sequences(sequences, maxlen=200)\n",
    "\n",
    "# Convert target labels to binary format\n",
    "\n",
    "targets = np.array(df['sentiment'])\n",
    "targets = np.where(targets==1, 1, 0)\n",
    "\n",
    "# Define the model architecture\n",
    "\n",
    "model = keras.Sequential([\n",
    "    Embedding(10000, 16, input_length=200),\n",
    "    LSTM(16),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "\n",
    "model.fit(padded_sequences, targets, epochs=10, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model on test data\n",
    "\n",
    "test_sequences = tokenizer.texts_to_sequences(['your test data goes here'])\n",
    "padded_test_sequences = keras.preprocessing.sequence.pad_sequences(test_sequences, maxlen=200)\n",
    "predictions = model.predict(padded_test_sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae333a7d",
   "metadata": {},
   "source": [
    "## Gated Recurrent Unit (GRU)\n",
    "\n",
    "Gated Recurrent Unit (GRU) is a type of recurrent neural network (RNN) architecture that is similar to LSTM but has fewer parameters, making it faster to train and less prone to overfitting. GRUs also use gating mechanisms to control the flow of information, but unlike LSTMs, they have only two gates: reset and update gates. The reset gate helps the network decide how to combine the new input with the previous hidden state, while the update gate helps the network decide how much of the previous hidden state to keep and how much to discard. Overall, GRUs have shown promising results in various natural language processing (NLP) tasks such as language translation and text classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "8625619e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1240/1240 [==============================] - 116s 89ms/step - loss: 0.3742 - accuracy: 0.8286 - val_loss: 0.2885 - val_accuracy: 0.8862\n",
      "Epoch 2/10\n",
      "1240/1240 [==============================] - 103s 83ms/step - loss: 0.2335 - accuracy: 0.9103 - val_loss: 0.2866 - val_accuracy: 0.8829\n",
      "Epoch 3/10\n",
      "1240/1240 [==============================] - 104s 84ms/step - loss: 0.1952 - accuracy: 0.9265 - val_loss: 0.2985 - val_accuracy: 0.8832\n",
      "Epoch 4/10\n",
      "1240/1240 [==============================] - 105s 84ms/step - loss: 0.1683 - accuracy: 0.9394 - val_loss: 0.3140 - val_accuracy: 0.8793\n",
      "Epoch 5/10\n",
      "1240/1240 [==============================] - 104s 84ms/step - loss: 0.1422 - accuracy: 0.9501 - val_loss: 0.3488 - val_accuracy: 0.8675\n",
      "Epoch 6/10\n",
      "1240/1240 [==============================] - 102s 83ms/step - loss: 0.1197 - accuracy: 0.9596 - val_loss: 0.3888 - val_accuracy: 0.8676\n",
      "Epoch 7/10\n",
      "1240/1240 [==============================] - 131s 106ms/step - loss: 0.1076 - accuracy: 0.9644 - val_loss: 0.3997 - val_accuracy: 0.8687\n",
      "Epoch 8/10\n",
      "1240/1240 [==============================] - 120s 97ms/step - loss: 0.0927 - accuracy: 0.9706 - val_loss: 0.4252 - val_accuracy: 0.8685\n",
      "Epoch 9/10\n",
      "1240/1240 [==============================] - 115s 93ms/step - loss: 0.0852 - accuracy: 0.9735 - val_loss: 0.4511 - val_accuracy: 0.8647\n",
      "Epoch 10/10\n",
      "1240/1240 [==============================] - 108s 87ms/step - loss: 0.0708 - accuracy: 0.9784 - val_loss: 0.4897 - val_accuracy: 0.8639\n",
      "1/1 [==============================] - 3s 3s/step\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Embedding, GRU, Dense\n",
    "\n",
    "# Convert the tokenized text data to sequences of integers\n",
    "\n",
    "tokenizer = keras.preprocessing.text.Tokenizer(num_words=10000)\n",
    "tokenizer.fit_on_texts(df['GRAMS'])\n",
    "sequences = tokenizer.texts_to_sequences(df['GRAMS'])\n",
    "\n",
    "# Pad sequences to have same length\n",
    "\n",
    "padded_sequences = keras.preprocessing.sequence.pad_sequences(sequences, maxlen=200)\n",
    "\n",
    "# Convert target labels to binary format\n",
    "\n",
    "targets = np.array(df['sentiment'])\n",
    "targets = np.where(targets==1, 1, 0)\n",
    "\n",
    "# Define the model architecture\n",
    "\n",
    "model = keras.Sequential([\n",
    "    Embedding(10000, 16, input_length=200),\n",
    "    GRU(16),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "\n",
    "model.fit(padded_sequences, targets, epochs=10, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model on test data\n",
    "\n",
    "test_sequences = tokenizer.texts_to_sequences(['your test data goes here'])\n",
    "padded_test_sequences = keras.preprocessing.sequence.pad_sequences(test_sequences, maxlen=200)\n",
    "predictions = model.predict(padded_test_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe62ca2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
